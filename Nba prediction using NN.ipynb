{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Prediction of NBA Win/Loss using Neural Networks\n",
    "\n",
    "\n",
    "Lets first load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.datasets import imdb\n",
    "from keras import initializers\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect(r'Driver={SQL Server};Server=localhost;Database=nba;Trusted_Connection=yes;')\n",
    "sql = \"select * from Game_Stats\"\n",
    "df1 = pd.read_sql(sql, cnxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Find the number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23096, 21)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Lets look at the columns\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Field goal percentage for home team\n",
    "   2. Free throw percentage for home team\n",
    "   3. 3pt Field goal percentage for home team\n",
    "   4. Assists for home team\n",
    "   5. Rebounds for home team\n",
    "   6. Field goal percentage for away team\n",
    "   7. Assists for away team\n",
    "   8. Rebounds for away team\n",
    "   9. Win or Loss (1 or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_STATUS_TEXT</th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>VISITOR_TEAM_ID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEAM_ID_home</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>...</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>TEAM_ID_away</th>\n",
       "      <th>PTS_away</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>21900895</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>2019</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>85</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.900</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>93</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.226</td>\n",
       "      <td>20</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>21900896</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>2019</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>91</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.400</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>111</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.275</td>\n",
       "      <td>28</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>21900897</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>2019</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>136</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.805</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>130</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.488</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>21900898</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>1610612761</td>\n",
       "      <td>2019</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>133</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.700</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>1610612761</td>\n",
       "      <td>118</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.263</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>21900899</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>2019</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>106</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.885</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>51</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>100</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.429</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  GAME_DATE_EST   GAME_ID GAME_STATUS_TEXT  HOME_TEAM_ID  VISITOR_TEAM_ID  \\\n",
       "0      1/3/2020  21900895            Final    1610612766       1610612749   \n",
       "1      1/3/2020  21900896            Final    1610612750       1610612742   \n",
       "2      1/3/2020  21900897            Final    1610612746       1610612755   \n",
       "3      1/3/2020  21900898            Final    1610612743       1610612761   \n",
       "4      1/3/2020  21900899            Final    1610612758       1610612765   \n",
       "\n",
       "   SEASON  TEAM_ID_home  PTS_home  FG_PCT_home  FT_PCT_home  ...  AST_home  \\\n",
       "0    2019    1610612766        85        0.354        0.900  ...        22   \n",
       "1    2019    1610612750        91        0.364        0.400  ...        19   \n",
       "2    2019    1610612746       136        0.592        0.805  ...        25   \n",
       "3    2019    1610612743       133        0.566        0.700  ...        38   \n",
       "4    2019    1610612758       106        0.407        0.885  ...        18   \n",
       "\n",
       "   REB_home  TEAM_ID_away  PTS_away  FG_PCT_away  FT_PCT_away  FG3_PCT_away  \\\n",
       "0        47    1610612749        93        0.402        0.762         0.226   \n",
       "1        57    1610612742       111        0.468        0.632         0.275   \n",
       "2        37    1610612755       130        0.505        0.650         0.488   \n",
       "3        41    1610612761       118        0.461        0.897         0.263   \n",
       "4        51    1610612765       100        0.413        0.667         0.429   \n",
       "\n",
       "   AST_away  REB_away  HOME_TEAM_WINS  \n",
       "0        20        61               0  \n",
       "1        28        56               0  \n",
       "2        27        37               1  \n",
       "3        24        36               1  \n",
       "4        23        42               1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the features and split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1[['FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home', 'FG_PCT_away','AST_away', 'REB_away']]\n",
    "y = df1['HOME_TEAM_WINS']\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a RandomForest model as a Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.830\n",
      "roc-auc is 0.910\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Neural Network model with one hidden layer with sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6842 - accuracy: 0.5934 - val_loss: 0.6201 - val_accuracy: 0.6437\n",
      "Epoch 2/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.6056 - accuracy: 0.7009 - val_loss: 0.5957 - val_accuracy: 0.7227\n",
      "Epoch 3/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5882 - accuracy: 0.7271 - val_loss: 0.5788 - val_accuracy: 0.7247\n",
      "Epoch 4/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5760 - accuracy: 0.7337 - val_loss: 0.5674 - val_accuracy: 0.7307\n",
      "Epoch 5/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5663 - accuracy: 0.7393 - val_loss: 0.5603 - val_accuracy: 0.7338\n",
      "Epoch 6/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5584 - accuracy: 0.7401 - val_loss: 0.5545 - val_accuracy: 0.7338\n",
      "Epoch 7/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5523 - accuracy: 0.7422 - val_loss: 0.5497 - val_accuracy: 0.7361\n",
      "Epoch 8/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5470 - accuracy: 0.7438 - val_loss: 0.5417 - val_accuracy: 0.7379\n",
      "Epoch 9/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5428 - accuracy: 0.7437 - val_loss: 0.5382 - val_accuracy: 0.7398\n",
      "Epoch 10/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5396 - accuracy: 0.7423 - val_loss: 0.5379 - val_accuracy: 0.7374\n",
      "Epoch 11/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5373 - accuracy: 0.7439 - val_loss: 0.5341 - val_accuracy: 0.7398\n",
      "Epoch 12/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5348 - accuracy: 0.7439 - val_loss: 0.5345 - val_accuracy: 0.7426\n",
      "Epoch 13/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5337 - accuracy: 0.7442 - val_loss: 0.5320 - val_accuracy: 0.7374\n",
      "Epoch 14/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5325 - accuracy: 0.7446 - val_loss: 0.5311 - val_accuracy: 0.7400\n",
      "Epoch 15/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5308 - accuracy: 0.7466 - val_loss: 0.5288 - val_accuracy: 0.7385\n",
      "Epoch 16/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5303 - accuracy: 0.7449 - val_loss: 0.5278 - val_accuracy: 0.7394\n",
      "Epoch 17/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5293 - accuracy: 0.7464 - val_loss: 0.5263 - val_accuracy: 0.7409\n",
      "Epoch 18/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5286 - accuracy: 0.7462 - val_loss: 0.5379 - val_accuracy: 0.7290\n",
      "Epoch 19/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5272 - accuracy: 0.7450 - val_loss: 0.5265 - val_accuracy: 0.7424\n",
      "Epoch 20/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7451 - val_loss: 0.5252 - val_accuracy: 0.7435\n",
      "Epoch 21/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5254 - accuracy: 0.7453 - val_loss: 0.5236 - val_accuracy: 0.7433\n",
      "Epoch 22/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5244 - accuracy: 0.7458 - val_loss: 0.5398 - val_accuracy: 0.7286\n",
      "Epoch 23/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5236 - accuracy: 0.7439 - val_loss: 0.5225 - val_accuracy: 0.7416\n",
      "Epoch 24/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5226 - accuracy: 0.7439 - val_loss: 0.5216 - val_accuracy: 0.7424\n",
      "Epoch 25/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5222 - accuracy: 0.7459 - val_loss: 0.5228 - val_accuracy: 0.7429\n",
      "Epoch 26/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5215 - accuracy: 0.7468 - val_loss: 0.5235 - val_accuracy: 0.7418\n",
      "Epoch 27/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5207 - accuracy: 0.7445 - val_loss: 0.5191 - val_accuracy: 0.7418\n",
      "Epoch 28/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5193 - accuracy: 0.7455 - val_loss: 0.5203 - val_accuracy: 0.7429\n",
      "Epoch 29/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5193 - accuracy: 0.7449 - val_loss: 0.5183 - val_accuracy: 0.7422\n",
      "Epoch 30/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.7441 - val_loss: 0.5186 - val_accuracy: 0.7420\n",
      "Epoch 31/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5183 - accuracy: 0.7445 - val_loss: 0.5177 - val_accuracy: 0.7424\n",
      "Epoch 32/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5184 - accuracy: 0.7459 - val_loss: 0.5177 - val_accuracy: 0.7424\n",
      "Epoch 33/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5175 - accuracy: 0.7452 - val_loss: 0.5180 - val_accuracy: 0.7422\n",
      "Epoch 34/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5176 - accuracy: 0.7442 - val_loss: 0.5161 - val_accuracy: 0.7439\n",
      "Epoch 35/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7457 - val_loss: 0.5157 - val_accuracy: 0.7433\n",
      "Epoch 36/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5174 - accuracy: 0.7448 - val_loss: 0.5194 - val_accuracy: 0.7431\n",
      "Epoch 37/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5167 - accuracy: 0.7451 - val_loss: 0.5155 - val_accuracy: 0.7420\n",
      "Epoch 38/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5164 - accuracy: 0.7455 - val_loss: 0.5176 - val_accuracy: 0.7442\n",
      "Epoch 39/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5161 - accuracy: 0.7465 - val_loss: 0.5149 - val_accuracy: 0.7437\n",
      "Epoch 40/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5156 - accuracy: 0.7444 - val_loss: 0.5263 - val_accuracy: 0.7379\n",
      "Epoch 41/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5156 - accuracy: 0.7455 - val_loss: 0.5145 - val_accuracy: 0.7426\n",
      "Epoch 42/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5161 - accuracy: 0.7461 - val_loss: 0.5144 - val_accuracy: 0.7431\n",
      "Epoch 43/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5153 - accuracy: 0.7456 - val_loss: 0.5156 - val_accuracy: 0.7433\n",
      "Epoch 44/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5150 - accuracy: 0.7456 - val_loss: 0.5175 - val_accuracy: 0.7433\n",
      "Epoch 45/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5147 - accuracy: 0.7459 - val_loss: 0.5141 - val_accuracy: 0.7435\n",
      "Epoch 46/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5147 - accuracy: 0.7452 - val_loss: 0.5195 - val_accuracy: 0.7435\n",
      "Epoch 47/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5149 - accuracy: 0.7446 - val_loss: 0.5136 - val_accuracy: 0.7431\n",
      "Epoch 48/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5147 - accuracy: 0.7446 - val_loss: 0.5157 - val_accuracy: 0.7433\n",
      "Epoch 49/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5145 - accuracy: 0.7447 - val_loss: 0.5223 - val_accuracy: 0.7429\n",
      "Epoch 50/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5141 - accuracy: 0.7462 - val_loss: 0.5163 - val_accuracy: 0.7442\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X_test)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.744\n",
      "roc-auc is 0.815\n"
     ]
    }
   ],
   "source": [
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20b9998fbe0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add two hidden layers to the Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 277\n",
      "Trainable params: 277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(12,activation='sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6852 - accuracy: 0.5913 - val_loss: 0.6715 - val_accuracy: 0.6093\n",
      "Epoch 2/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6779 - accuracy: 0.5913 - val_loss: 0.6706 - val_accuracy: 0.6093\n",
      "Epoch 3/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6769 - accuracy: 0.5913 - val_loss: 0.6700 - val_accuracy: 0.6093\n",
      "Epoch 4/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6763 - accuracy: 0.5913 - val_loss: 0.6695 - val_accuracy: 0.6093\n",
      "Epoch 5/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6757 - accuracy: 0.5913 - val_loss: 0.6684 - val_accuracy: 0.6093\n",
      "Epoch 6/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.6744 - accuracy: 0.5913 - val_loss: 0.6668 - val_accuracy: 0.6093\n",
      "Epoch 7/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.6715 - accuracy: 0.5913 - val_loss: 0.6630 - val_accuracy: 0.6093\n",
      "Epoch 8/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.6674 - accuracy: 0.5913 - val_loss: 0.6590 - val_accuracy: 0.6093\n",
      "Epoch 9/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.6631 - accuracy: 0.5913 - val_loss: 0.6551 - val_accuracy: 0.6093\n",
      "Epoch 10/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.6591 - accuracy: 0.5913 - val_loss: 0.6512 - val_accuracy: 0.6093\n",
      "Epoch 11/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6548 - accuracy: 0.5913 - val_loss: 0.6466 - val_accuracy: 0.6093\n",
      "Epoch 12/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6494 - accuracy: 0.5913 - val_loss: 0.6403 - val_accuracy: 0.6093\n",
      "Epoch 13/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.6427 - accuracy: 0.5913 - val_loss: 0.6343 - val_accuracy: 0.6093\n",
      "Epoch 14/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6361 - accuracy: 0.5918 - val_loss: 0.6266 - val_accuracy: 0.6173\n",
      "Epoch 15/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.6244 - accuracy: 0.6515 - val_loss: 0.6148 - val_accuracy: 0.6792\n",
      "Epoch 16/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.6148 - accuracy: 0.6899 - val_loss: 0.6062 - val_accuracy: 0.7206\n",
      "Epoch 17/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.6061 - accuracy: 0.7211 - val_loss: 0.5981 - val_accuracy: 0.7333\n",
      "Epoch 18/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.7333 - val_loss: 0.5909 - val_accuracy: 0.7323\n",
      "Epoch 19/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.7374 - val_loss: 0.5825 - val_accuracy: 0.7364\n",
      "Epoch 20/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5828 - accuracy: 0.7386 - val_loss: 0.5757 - val_accuracy: 0.7340\n",
      "Epoch 21/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5758 - accuracy: 0.7402 - val_loss: 0.5695 - val_accuracy: 0.7390\n",
      "Epoch 22/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7435 - val_loss: 0.5636 - val_accuracy: 0.7355\n",
      "Epoch 23/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7436 - val_loss: 0.5587 - val_accuracy: 0.7387\n",
      "Epoch 24/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5585 - accuracy: 0.7436 - val_loss: 0.5543 - val_accuracy: 0.7385\n",
      "Epoch 25/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5538 - accuracy: 0.7457 - val_loss: 0.5503 - val_accuracy: 0.7372\n",
      "Epoch 26/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5499 - accuracy: 0.7453 - val_loss: 0.5460 - val_accuracy: 0.7420\n",
      "Epoch 27/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5461 - accuracy: 0.7465 - val_loss: 0.5422 - val_accuracy: 0.7426\n",
      "Epoch 28/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7442 - val_loss: 0.5394 - val_accuracy: 0.7422\n",
      "Epoch 29/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5403 - accuracy: 0.7456 - val_loss: 0.5371 - val_accuracy: 0.7411\n",
      "Epoch 30/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5377 - accuracy: 0.7447 - val_loss: 0.5347 - val_accuracy: 0.7409\n",
      "Epoch 31/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5352 - accuracy: 0.7454 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 32/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5336 - accuracy: 0.7460 - val_loss: 0.5327 - val_accuracy: 0.7377\n",
      "Epoch 33/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5315 - accuracy: 0.7467 - val_loss: 0.5304 - val_accuracy: 0.7372\n",
      "Epoch 34/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5301 - accuracy: 0.7456 - val_loss: 0.5280 - val_accuracy: 0.7426\n",
      "Epoch 35/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5285 - accuracy: 0.7463 - val_loss: 0.5260 - val_accuracy: 0.7444\n",
      "Epoch 36/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5269 - accuracy: 0.7464 - val_loss: 0.5258 - val_accuracy: 0.7424\n",
      "Epoch 37/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5255 - accuracy: 0.7473 - val_loss: 0.5240 - val_accuracy: 0.7433\n",
      "Epoch 38/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5244 - accuracy: 0.7463 - val_loss: 0.5244 - val_accuracy: 0.7407\n",
      "Epoch 39/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.7466 - val_loss: 0.5215 - val_accuracy: 0.7442\n",
      "Epoch 40/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5222 - accuracy: 0.7460 - val_loss: 0.5216 - val_accuracy: 0.7424\n",
      "Epoch 41/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7465 - val_loss: 0.5203 - val_accuracy: 0.7435\n",
      "Epoch 42/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5204 - accuracy: 0.7465 - val_loss: 0.5212 - val_accuracy: 0.7433\n",
      "Epoch 43/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7490 - val_loss: 0.5185 - val_accuracy: 0.7426\n",
      "Epoch 44/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.7465 - val_loss: 0.5190 - val_accuracy: 0.7435\n",
      "Epoch 45/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7477 - val_loss: 0.5171 - val_accuracy: 0.7429\n",
      "Epoch 46/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.7450 - val_loss: 0.5174 - val_accuracy: 0.7416\n",
      "Epoch 47/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7445 - val_loss: 0.5164 - val_accuracy: 0.7435\n",
      "Epoch 48/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5163 - accuracy: 0.7457 - val_loss: 0.5160 - val_accuracy: 0.7433\n",
      "Epoch 49/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5160 - accuracy: 0.7468 - val_loss: 0.5181 - val_accuracy: 0.7429\n",
      "Epoch 50/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7464 - val_loss: 0.5148 - val_accuracy: 0.7424\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.742\n",
      "roc-auc is 0.817\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X_test)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20b9655e520>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change to two hidden layers with activation relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 277\n",
      "Trainable params: 277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'relu'))\n",
    "model_1.add(Dense(12,activation='relu'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5783 - accuracy: 0.7044 - val_loss: 0.6210 - val_accuracy: 0.6708\n",
      "Epoch 2/50\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7317 - val_loss: 0.5453 - val_accuracy: 0.7234\n",
      "Epoch 3/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5207 - accuracy: 0.7386 - val_loss: 0.5101 - val_accuracy: 0.7431\n",
      "Epoch 4/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5156 - accuracy: 0.7384 - val_loss: 0.5126 - val_accuracy: 0.7413\n",
      "Epoch 5/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5141 - accuracy: 0.7407 - val_loss: 0.5161 - val_accuracy: 0.7368\n",
      "Epoch 6/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5118 - accuracy: 0.7430 - val_loss: 0.5031 - val_accuracy: 0.7452\n",
      "Epoch 7/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5129 - accuracy: 0.7437 - val_loss: 0.5151 - val_accuracy: 0.7392\n",
      "Epoch 8/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5117 - accuracy: 0.7422 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 9/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5112 - accuracy: 0.7460 - val_loss: 0.5372 - val_accuracy: 0.7242\n",
      "Epoch 10/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5102 - accuracy: 0.7447 - val_loss: 0.5073 - val_accuracy: 0.7405\n",
      "Epoch 11/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5101 - accuracy: 0.7464 - val_loss: 0.5202 - val_accuracy: 0.7325\n",
      "Epoch 12/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5107 - accuracy: 0.7431 - val_loss: 0.5133 - val_accuracy: 0.7390\n",
      "Epoch 13/50\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5096 - accuracy: 0.7421 - val_loss: 0.5198 - val_accuracy: 0.7368\n",
      "Epoch 14/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5093 - accuracy: 0.7425 - val_loss: 0.5033 - val_accuracy: 0.7446\n",
      "Epoch 15/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5094 - accuracy: 0.7441 - val_loss: 0.5083 - val_accuracy: 0.7420\n",
      "Epoch 16/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5094 - accuracy: 0.7425 - val_loss: 0.5030 - val_accuracy: 0.7461\n",
      "Epoch 17/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5080 - accuracy: 0.7455 - val_loss: 0.5048 - val_accuracy: 0.7435\n",
      "Epoch 18/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5081 - accuracy: 0.7435 - val_loss: 0.5021 - val_accuracy: 0.7448\n",
      "Epoch 19/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5088 - accuracy: 0.7450 - val_loss: 0.5026 - val_accuracy: 0.7463\n",
      "Epoch 20/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5085 - accuracy: 0.7447 - val_loss: 0.5032 - val_accuracy: 0.7472\n",
      "Epoch 21/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5082 - accuracy: 0.7465 - val_loss: 0.5025 - val_accuracy: 0.7437\n",
      "Epoch 22/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5076 - accuracy: 0.7466 - val_loss: 0.5019 - val_accuracy: 0.7461\n",
      "Epoch 23/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5082 - accuracy: 0.7457 - val_loss: 0.5021 - val_accuracy: 0.7442\n",
      "Epoch 24/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5071 - accuracy: 0.7447 - val_loss: 0.5099 - val_accuracy: 0.7411\n",
      "Epoch 25/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5078 - accuracy: 0.7456 - val_loss: 0.5022 - val_accuracy: 0.7455\n",
      "Epoch 26/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5080 - accuracy: 0.7444 - val_loss: 0.5078 - val_accuracy: 0.7416\n",
      "Epoch 27/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5082 - accuracy: 0.7438 - val_loss: 0.5225 - val_accuracy: 0.7320\n",
      "Epoch 28/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5074 - accuracy: 0.7449 - val_loss: 0.5092 - val_accuracy: 0.7407\n",
      "Epoch 29/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5073 - accuracy: 0.7465 - val_loss: 0.5520 - val_accuracy: 0.7173\n",
      "Epoch 30/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5082 - accuracy: 0.7440 - val_loss: 0.5081 - val_accuracy: 0.7416\n",
      "Epoch 31/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5075 - accuracy: 0.7456 - val_loss: 0.5087 - val_accuracy: 0.7403\n",
      "Epoch 32/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5074 - accuracy: 0.7454 - val_loss: 0.5146 - val_accuracy: 0.7387\n",
      "Epoch 33/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5073 - accuracy: 0.7460 - val_loss: 0.5215 - val_accuracy: 0.7323\n",
      "Epoch 34/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5070 - accuracy: 0.7465 - val_loss: 0.5185 - val_accuracy: 0.7346\n",
      "Epoch 35/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5076 - accuracy: 0.7471 - val_loss: 0.5019 - val_accuracy: 0.7439\n",
      "Epoch 36/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5063 - accuracy: 0.7449 - val_loss: 0.5027 - val_accuracy: 0.7457\n",
      "Epoch 37/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5071 - accuracy: 0.7464 - val_loss: 0.5019 - val_accuracy: 0.7463\n",
      "Epoch 38/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5060 - accuracy: 0.7480 - val_loss: 0.5022 - val_accuracy: 0.7463\n",
      "Epoch 39/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5070 - accuracy: 0.7459 - val_loss: 0.5022 - val_accuracy: 0.7455\n",
      "Epoch 40/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5059 - accuracy: 0.7453 - val_loss: 0.5032 - val_accuracy: 0.7461\n",
      "Epoch 41/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5077 - accuracy: 0.7443 - val_loss: 0.5024 - val_accuracy: 0.7446\n",
      "Epoch 42/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5068 - accuracy: 0.7464 - val_loss: 0.5061 - val_accuracy: 0.7431\n",
      "Epoch 43/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5071 - accuracy: 0.7466 - val_loss: 0.5034 - val_accuracy: 0.7455\n",
      "Epoch 44/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5059 - accuracy: 0.7458 - val_loss: 0.5054 - val_accuracy: 0.7429\n",
      "Epoch 45/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5064 - accuracy: 0.7478 - val_loss: 0.5253 - val_accuracy: 0.7323\n",
      "Epoch 46/50\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5065 - accuracy: 0.7462 - val_loss: 0.5016 - val_accuracy: 0.7457\n",
      "Epoch 47/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5059 - accuracy: 0.7477 - val_loss: 0.5292 - val_accuracy: 0.7264\n",
      "Epoch 48/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5063 - accuracy: 0.7468 - val_loss: 0.5117 - val_accuracy: 0.7398\n",
      "Epoch 49/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5067 - accuracy: 0.7482 - val_loss: 0.5121 - val_accuracy: 0.7407\n",
      "Epoch 50/50\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5066 - accuracy: 0.7456 - val_loss: 0.5075 - val_accuracy: 0.7424\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.742\n",
      "roc-auc is 0.819\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X_test)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20b926b54f0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change to epochs 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5067 - accuracy: 0.7458 - val_loss: 0.5023 - val_accuracy: 0.7457\n",
      "Epoch 2/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7466 - val_loss: 0.5027 - val_accuracy: 0.7459\n",
      "Epoch 3/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.7467 - val_loss: 0.5072 - val_accuracy: 0.7424\n",
      "Epoch 4/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5066 - accuracy: 0.7458 - val_loss: 0.5050 - val_accuracy: 0.7455\n",
      "Epoch 5/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5064 - accuracy: 0.7459 - val_loss: 0.5083 - val_accuracy: 0.7403\n",
      "Epoch 6/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5057 - accuracy: 0.7453 - val_loss: 0.5095 - val_accuracy: 0.7405\n",
      "Epoch 7/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5060 - accuracy: 0.7463 - val_loss: 0.5078 - val_accuracy: 0.7407\n",
      "Epoch 8/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5055 - accuracy: 0.7485 - val_loss: 0.5031 - val_accuracy: 0.7465\n",
      "Epoch 9/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5060 - accuracy: 0.7459 - val_loss: 0.5016 - val_accuracy: 0.7461\n",
      "Epoch 10/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5060 - accuracy: 0.7460 - val_loss: 0.5127 - val_accuracy: 0.7409\n",
      "Epoch 11/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5067 - accuracy: 0.7448 - val_loss: 0.5027 - val_accuracy: 0.7470\n",
      "Epoch 12/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5060 - accuracy: 0.7458 - val_loss: 0.5055 - val_accuracy: 0.7439\n",
      "Epoch 13/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5055 - accuracy: 0.7482 - val_loss: 0.5038 - val_accuracy: 0.7474\n",
      "Epoch 14/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5050 - accuracy: 0.7459 - val_loss: 0.5110 - val_accuracy: 0.7416\n",
      "Epoch 15/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5063 - accuracy: 0.7481 - val_loss: 0.5134 - val_accuracy: 0.7407\n",
      "Epoch 16/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5050 - accuracy: 0.7457 - val_loss: 0.5021 - val_accuracy: 0.7470\n",
      "Epoch 17/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5055 - accuracy: 0.7491 - val_loss: 0.5116 - val_accuracy: 0.7407\n",
      "Epoch 18/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.7464 - val_loss: 0.5096 - val_accuracy: 0.7431\n",
      "Epoch 19/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7472 - val_loss: 0.5024 - val_accuracy: 0.7470\n",
      "Epoch 20/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7466 - val_loss: 0.5153 - val_accuracy: 0.7379\n",
      "Epoch 21/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7465 - val_loss: 0.5029 - val_accuracy: 0.7465\n",
      "Epoch 22/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5061 - accuracy: 0.7465 - val_loss: 0.5009 - val_accuracy: 0.7470\n",
      "Epoch 23/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.7476 - val_loss: 0.5036 - val_accuracy: 0.7463\n",
      "Epoch 24/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5048 - accuracy: 0.7479 - val_loss: 0.5134 - val_accuracy: 0.7409\n",
      "Epoch 25/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5060 - accuracy: 0.7469 - val_loss: 0.5011 - val_accuracy: 0.7474\n",
      "Epoch 26/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5063 - accuracy: 0.7457 - val_loss: 0.5154 - val_accuracy: 0.7392\n",
      "Epoch 27/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5055 - accuracy: 0.7474 - val_loss: 0.5007 - val_accuracy: 0.7472\n",
      "Epoch 28/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5051 - accuracy: 0.7477 - val_loss: 0.5023 - val_accuracy: 0.7465\n",
      "Epoch 29/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5048 - accuracy: 0.7469 - val_loss: 0.5017 - val_accuracy: 0.7481\n",
      "Epoch 30/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5045 - accuracy: 0.7485 - val_loss: 0.5017 - val_accuracy: 0.7496\n",
      "Epoch 31/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5053 - accuracy: 0.7480 - val_loss: 0.5010 - val_accuracy: 0.7483\n",
      "Epoch 32/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5047 - accuracy: 0.7491 - val_loss: 0.5035 - val_accuracy: 0.7465\n",
      "Epoch 33/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5052 - accuracy: 0.7462 - val_loss: 0.5009 - val_accuracy: 0.7470\n",
      "Epoch 34/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5048 - accuracy: 0.7477 - val_loss: 0.5065 - val_accuracy: 0.7405\n",
      "Epoch 35/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5049 - accuracy: 0.7489 - val_loss: 0.5010 - val_accuracy: 0.7474\n",
      "Epoch 36/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5047 - accuracy: 0.7473 - val_loss: 0.5053 - val_accuracy: 0.7409\n",
      "Epoch 37/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5044 - accuracy: 0.7460 - val_loss: 0.5050 - val_accuracy: 0.7409\n",
      "Epoch 38/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5048 - accuracy: 0.7474 - val_loss: 0.5039 - val_accuracy: 0.7452\n",
      "Epoch 39/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5049 - accuracy: 0.7459 - val_loss: 0.5055 - val_accuracy: 0.7437\n",
      "Epoch 40/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5042 - accuracy: 0.7497 - val_loss: 0.4999 - val_accuracy: 0.7452\n",
      "Epoch 41/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5045 - accuracy: 0.7476 - val_loss: 0.4994 - val_accuracy: 0.7465\n",
      "Epoch 42/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5042 - accuracy: 0.7488 - val_loss: 0.4990 - val_accuracy: 0.7481\n",
      "Epoch 43/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5042 - accuracy: 0.7473 - val_loss: 0.5008 - val_accuracy: 0.7485\n",
      "Epoch 44/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5048 - accuracy: 0.7474 - val_loss: 0.5048 - val_accuracy: 0.7429\n",
      "Epoch 45/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5046 - accuracy: 0.7474 - val_loss: 0.5023 - val_accuracy: 0.7465\n",
      "Epoch 46/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5038 - accuracy: 0.7467 - val_loss: 0.5018 - val_accuracy: 0.7461\n",
      "Epoch 47/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5043 - accuracy: 0.7475 - val_loss: 0.5023 - val_accuracy: 0.7459\n",
      "Epoch 48/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5039 - accuracy: 0.7450 - val_loss: 0.4991 - val_accuracy: 0.7476\n",
      "Epoch 49/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5041 - accuracy: 0.7485 - val_loss: 0.4990 - val_accuracy: 0.7474\n",
      "Epoch 50/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5036 - accuracy: 0.7485 - val_loss: 0.4996 - val_accuracy: 0.7476\n",
      "Epoch 51/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5041 - accuracy: 0.7484 - val_loss: 0.4997 - val_accuracy: 0.7461\n",
      "Epoch 52/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5045 - accuracy: 0.7471 - val_loss: 0.5002 - val_accuracy: 0.7485\n",
      "Epoch 53/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5038 - accuracy: 0.7464 - val_loss: 0.4998 - val_accuracy: 0.7470\n",
      "Epoch 54/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5045 - accuracy: 0.7457 - val_loss: 0.5318 - val_accuracy: 0.7242\n",
      "Epoch 55/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5037 - accuracy: 0.7485 - val_loss: 0.4998 - val_accuracy: 0.7485\n",
      "Epoch 56/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5038 - accuracy: 0.7457 - val_loss: 0.5006 - val_accuracy: 0.7485\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5042 - accuracy: 0.7466 - val_loss: 0.4989 - val_accuracy: 0.7476\n",
      "Epoch 58/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5039 - accuracy: 0.7485 - val_loss: 0.5030 - val_accuracy: 0.7439\n",
      "Epoch 59/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5039 - accuracy: 0.7457 - val_loss: 0.5179 - val_accuracy: 0.7340\n",
      "Epoch 60/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5039 - accuracy: 0.7489 - val_loss: 0.4989 - val_accuracy: 0.7478\n",
      "Epoch 61/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5036 - accuracy: 0.7474 - val_loss: 0.4994 - val_accuracy: 0.7476\n",
      "Epoch 62/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5043 - accuracy: 0.7445 - val_loss: 0.5276 - val_accuracy: 0.7268\n",
      "Epoch 63/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5036 - accuracy: 0.7468 - val_loss: 0.4995 - val_accuracy: 0.7489\n",
      "Epoch 64/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7485 - val_loss: 0.5046 - val_accuracy: 0.7433\n",
      "Epoch 65/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.7493 - val_loss: 0.5000 - val_accuracy: 0.7494\n",
      "Epoch 66/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5035 - accuracy: 0.7469 - val_loss: 0.5155 - val_accuracy: 0.7366\n",
      "Epoch 67/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5033 - accuracy: 0.7478 - val_loss: 0.4985 - val_accuracy: 0.7476\n",
      "Epoch 68/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5039 - accuracy: 0.7494 - val_loss: 0.5180 - val_accuracy: 0.7333\n",
      "Epoch 69/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5039 - accuracy: 0.7471 - val_loss: 0.4996 - val_accuracy: 0.7483\n",
      "Epoch 70/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5032 - accuracy: 0.7494 - val_loss: 0.4990 - val_accuracy: 0.7476\n",
      "Epoch 71/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5036 - accuracy: 0.7484 - val_loss: 0.5001 - val_accuracy: 0.7481\n",
      "Epoch 72/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5033 - accuracy: 0.7488 - val_loss: 0.5047 - val_accuracy: 0.7433\n",
      "Epoch 73/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5040 - accuracy: 0.7466 - val_loss: 0.4983 - val_accuracy: 0.7474\n",
      "Epoch 74/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7464 - val_loss: 0.5024 - val_accuracy: 0.7470\n",
      "Epoch 75/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5032 - accuracy: 0.7473 - val_loss: 0.4992 - val_accuracy: 0.7476\n",
      "Epoch 76/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5037 - accuracy: 0.7483 - val_loss: 0.4993 - val_accuracy: 0.7470\n",
      "Epoch 77/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5034 - accuracy: 0.7474 - val_loss: 0.5009 - val_accuracy: 0.7476\n",
      "Epoch 78/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5030 - accuracy: 0.7482 - val_loss: 0.5082 - val_accuracy: 0.7422\n",
      "Epoch 79/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5029 - accuracy: 0.7459 - val_loss: 0.4984 - val_accuracy: 0.7481\n",
      "Epoch 80/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5029 - accuracy: 0.7489 - val_loss: 0.5005 - val_accuracy: 0.7468\n",
      "Epoch 81/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5037 - accuracy: 0.7471 - val_loss: 0.4982 - val_accuracy: 0.7487\n",
      "Epoch 82/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5026 - accuracy: 0.7478 - val_loss: 0.5020 - val_accuracy: 0.7455\n",
      "Epoch 83/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5038 - accuracy: 0.7470 - val_loss: 0.5122 - val_accuracy: 0.7390\n",
      "Epoch 84/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5034 - accuracy: 0.7491 - val_loss: 0.4983 - val_accuracy: 0.7474\n",
      "Epoch 85/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5029 - accuracy: 0.7488 - val_loss: 0.5007 - val_accuracy: 0.7483\n",
      "Epoch 86/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5030 - accuracy: 0.7487 - val_loss: 0.5511 - val_accuracy: 0.7158\n",
      "Epoch 87/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5029 - accuracy: 0.7492 - val_loss: 0.4981 - val_accuracy: 0.7474\n",
      "Epoch 88/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5026 - accuracy: 0.7453 - val_loss: 0.5157 - val_accuracy: 0.7353\n",
      "Epoch 89/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5032 - accuracy: 0.7473 - val_loss: 0.4981 - val_accuracy: 0.7468\n",
      "Epoch 90/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5028 - accuracy: 0.7481 - val_loss: 0.5055 - val_accuracy: 0.7426\n",
      "Epoch 91/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5030 - accuracy: 0.7484 - val_loss: 0.5098 - val_accuracy: 0.7426\n",
      "Epoch 92/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5024 - accuracy: 0.7478 - val_loss: 0.4979 - val_accuracy: 0.7468\n",
      "Epoch 93/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5031 - accuracy: 0.7486 - val_loss: 0.5075 - val_accuracy: 0.7418\n",
      "Epoch 94/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5024 - accuracy: 0.7492 - val_loss: 0.4996 - val_accuracy: 0.7498\n",
      "Epoch 95/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5026 - accuracy: 0.7489 - val_loss: 0.4997 - val_accuracy: 0.7494\n",
      "Epoch 96/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5023 - accuracy: 0.7482 - val_loss: 0.4985 - val_accuracy: 0.7468\n",
      "Epoch 97/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5027 - accuracy: 0.7470 - val_loss: 0.4978 - val_accuracy: 0.7491\n",
      "Epoch 98/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5030 - accuracy: 0.7460 - val_loss: 0.4996 - val_accuracy: 0.7485\n",
      "Epoch 99/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5020 - accuracy: 0.7502 - val_loss: 0.5005 - val_accuracy: 0.7465\n",
      "Epoch 100/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.7496 - val_loss: 0.5255 - val_accuracy: 0.7290\n",
      "Epoch 101/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.7487 - val_loss: 0.5129 - val_accuracy: 0.7383\n",
      "Epoch 102/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7486 - val_loss: 0.4987 - val_accuracy: 0.7502\n",
      "Epoch 103/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7479 - val_loss: 0.4976 - val_accuracy: 0.7481\n",
      "Epoch 104/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.7481 - val_loss: 0.4978 - val_accuracy: 0.7504\n",
      "Epoch 105/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5025 - accuracy: 0.7481 - val_loss: 0.5003 - val_accuracy: 0.7468\n",
      "Epoch 106/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.7480 - val_loss: 0.4984 - val_accuracy: 0.7476\n",
      "Epoch 107/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.7478 - val_loss: 0.5101 - val_accuracy: 0.7403\n",
      "Epoch 108/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7472 - val_loss: 0.4976 - val_accuracy: 0.7483\n",
      "Epoch 109/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7475 - val_loss: 0.5113 - val_accuracy: 0.7403\n",
      "Epoch 110/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5020 - accuracy: 0.7482 - val_loss: 0.4978 - val_accuracy: 0.7485\n",
      "Epoch 111/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.7481 - val_loss: 0.5127 - val_accuracy: 0.7390\n",
      "Epoch 112/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5022 - accuracy: 0.7498 - val_loss: 0.4986 - val_accuracy: 0.7489\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5028 - accuracy: 0.7476 - val_loss: 0.5010 - val_accuracy: 0.7459\n",
      "Epoch 114/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5020 - accuracy: 0.7480 - val_loss: 0.4985 - val_accuracy: 0.7494\n",
      "Epoch 115/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5019 - accuracy: 0.7485 - val_loss: 0.4976 - val_accuracy: 0.7487\n",
      "Epoch 116/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5021 - accuracy: 0.7482 - val_loss: 0.5016 - val_accuracy: 0.7444\n",
      "Epoch 117/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5024 - accuracy: 0.7469 - val_loss: 0.4975 - val_accuracy: 0.7474\n",
      "Epoch 118/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5027 - accuracy: 0.7488 - val_loss: 0.5034 - val_accuracy: 0.7444\n",
      "Epoch 119/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5024 - accuracy: 0.7490 - val_loss: 0.4994 - val_accuracy: 0.7476\n",
      "Epoch 120/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5021 - accuracy: 0.7484 - val_loss: 0.4976 - val_accuracy: 0.7494\n",
      "Epoch 121/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.7482 - val_loss: 0.5176 - val_accuracy: 0.7314\n",
      "Epoch 122/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5022 - accuracy: 0.7483 - val_loss: 0.5081 - val_accuracy: 0.7413\n",
      "Epoch 123/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5022 - accuracy: 0.7483 - val_loss: 0.4968 - val_accuracy: 0.7496\n",
      "Epoch 124/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5018 - accuracy: 0.7486 - val_loss: 0.5027 - val_accuracy: 0.7465\n",
      "Epoch 125/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5015 - accuracy: 0.7501 - val_loss: 0.4990 - val_accuracy: 0.7487\n",
      "Epoch 126/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5013 - accuracy: 0.7488 - val_loss: 0.4975 - val_accuracy: 0.7502\n",
      "Epoch 127/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5019 - accuracy: 0.7486 - val_loss: 0.4969 - val_accuracy: 0.7468\n",
      "Epoch 128/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5017 - accuracy: 0.7497 - val_loss: 0.4988 - val_accuracy: 0.7481\n",
      "Epoch 129/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5021 - accuracy: 0.7477 - val_loss: 0.4996 - val_accuracy: 0.7461\n",
      "Epoch 130/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5014 - accuracy: 0.7488 - val_loss: 0.4970 - val_accuracy: 0.7474\n",
      "Epoch 131/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5020 - accuracy: 0.7477 - val_loss: 0.4996 - val_accuracy: 0.7470\n",
      "Epoch 132/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5018 - accuracy: 0.7490 - val_loss: 0.5102 - val_accuracy: 0.7418\n",
      "Epoch 133/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5023 - accuracy: 0.7497 - val_loss: 0.5054 - val_accuracy: 0.7442\n",
      "Epoch 134/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5014 - accuracy: 0.7510 - val_loss: 0.5343 - val_accuracy: 0.7249\n",
      "Epoch 135/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5017 - accuracy: 0.7482 - val_loss: 0.5010 - val_accuracy: 0.7468\n",
      "Epoch 136/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.5010 - accuracy: 0.7486 - val_loss: 0.4973 - val_accuracy: 0.7500\n",
      "Epoch 137/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5015 - accuracy: 0.7477 - val_loss: 0.5411 - val_accuracy: 0.7206\n",
      "Epoch 138/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5014 - accuracy: 0.7501 - val_loss: 0.5003 - val_accuracy: 0.7459\n",
      "Epoch 139/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5017 - accuracy: 0.7499 - val_loss: 0.5191 - val_accuracy: 0.7305\n",
      "Epoch 140/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5007 - accuracy: 0.7494 - val_loss: 0.4976 - val_accuracy: 0.7498\n",
      "Epoch 141/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5012 - accuracy: 0.7496 - val_loss: 0.4988 - val_accuracy: 0.7481\n",
      "Epoch 142/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7497 - val_loss: 0.4962 - val_accuracy: 0.7494\n",
      "Epoch 143/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.7512 - val_loss: 0.4966 - val_accuracy: 0.7498\n",
      "Epoch 144/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7482 - val_loss: 0.4965 - val_accuracy: 0.7509\n",
      "Epoch 145/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5011 - accuracy: 0.7498 - val_loss: 0.4971 - val_accuracy: 0.7491\n",
      "Epoch 146/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5010 - accuracy: 0.7499 - val_loss: 0.4986 - val_accuracy: 0.7489\n",
      "Epoch 147/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5012 - accuracy: 0.7491 - val_loss: 0.4980 - val_accuracy: 0.7487\n",
      "Epoch 148/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5013 - accuracy: 0.7478 - val_loss: 0.4978 - val_accuracy: 0.7485\n",
      "Epoch 149/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7489 - val_loss: 0.4960 - val_accuracy: 0.7502\n",
      "Epoch 150/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5010 - accuracy: 0.7513 - val_loss: 0.4963 - val_accuracy: 0.7489\n",
      "Epoch 151/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5016 - accuracy: 0.7478 - val_loss: 0.5013 - val_accuracy: 0.7444\n",
      "Epoch 152/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5014 - accuracy: 0.7499 - val_loss: 0.5049 - val_accuracy: 0.7444\n",
      "Epoch 153/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7504 - val_loss: 0.4959 - val_accuracy: 0.7496\n",
      "Epoch 154/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.7498 - val_loss: 0.5082 - val_accuracy: 0.7426\n",
      "Epoch 155/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7491 - val_loss: 0.4976 - val_accuracy: 0.7481\n",
      "Epoch 156/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5012 - accuracy: 0.7480 - val_loss: 0.4963 - val_accuracy: 0.7498\n",
      "Epoch 157/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7494 - val_loss: 0.4956 - val_accuracy: 0.7502\n",
      "Epoch 158/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5014 - accuracy: 0.7484 - val_loss: 0.4978 - val_accuracy: 0.7498\n",
      "Epoch 159/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5005 - accuracy: 0.7504 - val_loss: 0.4968 - val_accuracy: 0.7498\n",
      "Epoch 160/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7477 - val_loss: 0.5058 - val_accuracy: 0.7437\n",
      "Epoch 161/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.7497 - val_loss: 0.5146 - val_accuracy: 0.7340\n",
      "Epoch 162/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5012 - accuracy: 0.7484 - val_loss: 0.4959 - val_accuracy: 0.7491\n",
      "Epoch 163/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5010 - accuracy: 0.7498 - val_loss: 0.4954 - val_accuracy: 0.7506\n",
      "Epoch 164/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5008 - accuracy: 0.7489 - val_loss: 0.4969 - val_accuracy: 0.7481\n",
      "Epoch 165/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5004 - accuracy: 0.7493 - val_loss: 0.4949 - val_accuracy: 0.7502\n",
      "Epoch 166/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.7490 - val_loss: 0.4957 - val_accuracy: 0.7496\n",
      "Epoch 167/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.7489 - val_loss: 0.4992 - val_accuracy: 0.7478\n",
      "Epoch 168/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7503 - val_loss: 0.5000 - val_accuracy: 0.7465\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.7469 - val_loss: 0.5103 - val_accuracy: 0.7405\n",
      "Epoch 170/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5005 - accuracy: 0.7492 - val_loss: 0.4995 - val_accuracy: 0.7450\n",
      "Epoch 171/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5006 - accuracy: 0.7491 - val_loss: 0.4947 - val_accuracy: 0.7498\n",
      "Epoch 172/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5011 - accuracy: 0.7484 - val_loss: 0.4949 - val_accuracy: 0.7498\n",
      "Epoch 173/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.7496 - val_loss: 0.4949 - val_accuracy: 0.7511\n",
      "Epoch 174/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4997 - accuracy: 0.7499 - val_loss: 0.5014 - val_accuracy: 0.7478\n",
      "Epoch 175/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5002 - accuracy: 0.7497 - val_loss: 0.4950 - val_accuracy: 0.7504\n",
      "Epoch 176/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5005 - accuracy: 0.7497 - val_loss: 0.5008 - val_accuracy: 0.7452\n",
      "Epoch 177/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7495 - val_loss: 0.4980 - val_accuracy: 0.7481\n",
      "Epoch 178/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5010 - accuracy: 0.7499 - val_loss: 0.4955 - val_accuracy: 0.7526\n",
      "Epoch 179/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5000 - accuracy: 0.7504 - val_loss: 0.5151 - val_accuracy: 0.7329\n",
      "Epoch 180/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5009 - accuracy: 0.7473 - val_loss: 0.5081 - val_accuracy: 0.7418\n",
      "Epoch 181/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.7522 - val_loss: 0.4950 - val_accuracy: 0.7504\n",
      "Epoch 182/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.7515 - val_loss: 0.4978 - val_accuracy: 0.7465\n",
      "Epoch 183/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7488 - val_loss: 0.4992 - val_accuracy: 0.7457\n",
      "Epoch 184/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5000 - accuracy: 0.7513 - val_loss: 0.5111 - val_accuracy: 0.7370\n",
      "Epoch 185/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5003 - accuracy: 0.7485 - val_loss: 0.4958 - val_accuracy: 0.7506\n",
      "Epoch 186/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.7503 - val_loss: 0.4975 - val_accuracy: 0.7498\n",
      "Epoch 187/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.7486 - val_loss: 0.5140 - val_accuracy: 0.7357\n",
      "Epoch 188/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5002 - accuracy: 0.7482 - val_loss: 0.5284 - val_accuracy: 0.7286\n",
      "Epoch 189/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7507 - val_loss: 0.4950 - val_accuracy: 0.7496\n",
      "Epoch 190/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.7511 - val_loss: 0.4968 - val_accuracy: 0.7496\n",
      "Epoch 191/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5004 - accuracy: 0.7507 - val_loss: 0.4963 - val_accuracy: 0.7528\n",
      "Epoch 192/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.5000 - accuracy: 0.7502 - val_loss: 0.4974 - val_accuracy: 0.7494\n",
      "Epoch 193/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.5005 - accuracy: 0.7529 - val_loss: 0.4938 - val_accuracy: 0.7506\n",
      "Epoch 194/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4998 - accuracy: 0.7490 - val_loss: 0.4931 - val_accuracy: 0.7511\n",
      "Epoch 195/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5000 - accuracy: 0.7502 - val_loss: 0.4938 - val_accuracy: 0.7515\n",
      "Epoch 196/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4997 - accuracy: 0.7511 - val_loss: 0.5060 - val_accuracy: 0.7429\n",
      "Epoch 197/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4994 - accuracy: 0.7501 - val_loss: 0.4988 - val_accuracy: 0.7463\n",
      "Epoch 198/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4998 - accuracy: 0.7514 - val_loss: 0.4953 - val_accuracy: 0.7513\n",
      "Epoch 199/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4988 - accuracy: 0.7525 - val_loss: 0.5051 - val_accuracy: 0.7433\n",
      "Epoch 200/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.5003 - accuracy: 0.7511 - val_loss: 0.5059 - val_accuracy: 0.7439\n",
      "Epoch 201/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4999 - accuracy: 0.7522 - val_loss: 0.4968 - val_accuracy: 0.7515\n",
      "Epoch 202/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4985 - accuracy: 0.7523 - val_loss: 0.4958 - val_accuracy: 0.7496\n",
      "Epoch 203/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4995 - accuracy: 0.7517 - val_loss: 0.4948 - val_accuracy: 0.7530\n",
      "Epoch 204/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4997 - accuracy: 0.7508 - val_loss: 0.4931 - val_accuracy: 0.7509\n",
      "Epoch 205/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4998 - accuracy: 0.7496 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 206/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.7494 - val_loss: 0.4961 - val_accuracy: 0.7485\n",
      "Epoch 207/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4995 - accuracy: 0.7506 - val_loss: 0.4948 - val_accuracy: 0.7498\n",
      "Epoch 208/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4994 - accuracy: 0.7523 - val_loss: 0.4937 - val_accuracy: 0.7524\n",
      "Epoch 209/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4991 - accuracy: 0.7505 - val_loss: 0.4924 - val_accuracy: 0.7532\n",
      "Epoch 210/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4990 - accuracy: 0.7502 - val_loss: 0.4928 - val_accuracy: 0.7502\n",
      "Epoch 211/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7513 - val_loss: 0.4927 - val_accuracy: 0.7541\n",
      "Epoch 212/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.7512 - val_loss: 0.5034 - val_accuracy: 0.7465\n",
      "Epoch 213/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.7527 - val_loss: 0.4925 - val_accuracy: 0.7524\n",
      "Epoch 214/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.7535 - val_loss: 0.5020 - val_accuracy: 0.7435\n",
      "Epoch 215/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4993 - accuracy: 0.7479 - val_loss: 0.5066 - val_accuracy: 0.7422\n",
      "Epoch 216/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4990 - accuracy: 0.7518 - val_loss: 0.4920 - val_accuracy: 0.7513\n",
      "Epoch 217/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4989 - accuracy: 0.7501 - val_loss: 0.4939 - val_accuracy: 0.7502\n",
      "Epoch 218/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4986 - accuracy: 0.7500 - val_loss: 0.4968 - val_accuracy: 0.7474\n",
      "Epoch 219/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4981 - accuracy: 0.7501 - val_loss: 0.5111 - val_accuracy: 0.7366\n",
      "Epoch 220/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7502 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
      "Epoch 221/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4989 - accuracy: 0.7503 - val_loss: 0.5209 - val_accuracy: 0.7314\n",
      "Epoch 222/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4987 - accuracy: 0.7510 - val_loss: 0.4943 - val_accuracy: 0.7504\n",
      "Epoch 223/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.7495 - val_loss: 0.4916 - val_accuracy: 0.7528\n",
      "Epoch 224/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4985 - accuracy: 0.7498 - val_loss: 0.5019 - val_accuracy: 0.7470\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.7509 - val_loss: 0.4915 - val_accuracy: 0.7532\n",
      "Epoch 226/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.7503 - val_loss: 0.5154 - val_accuracy: 0.7320\n",
      "Epoch 227/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4990 - accuracy: 0.7484 - val_loss: 0.5048 - val_accuracy: 0.7433\n",
      "Epoch 228/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4984 - accuracy: 0.7525 - val_loss: 0.4936 - val_accuracy: 0.7506\n",
      "Epoch 229/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4985 - accuracy: 0.7530 - val_loss: 0.4923 - val_accuracy: 0.7519\n",
      "Epoch 230/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4985 - accuracy: 0.7533 - val_loss: 0.4940 - val_accuracy: 0.7515\n",
      "Epoch 231/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4987 - accuracy: 0.7498 - val_loss: 0.5181 - val_accuracy: 0.7325\n",
      "Epoch 232/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.7510 - val_loss: 0.5006 - val_accuracy: 0.7485\n",
      "Epoch 233/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4985 - accuracy: 0.7496 - val_loss: 0.5008 - val_accuracy: 0.7478\n",
      "Epoch 234/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4980 - accuracy: 0.7513 - val_loss: 0.5259 - val_accuracy: 0.7266\n",
      "Epoch 235/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4971 - accuracy: 0.7514 - val_loss: 0.4981 - val_accuracy: 0.7459\n",
      "Epoch 236/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4972 - accuracy: 0.7505 - val_loss: 0.5045 - val_accuracy: 0.7431\n",
      "Epoch 237/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.7506 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 238/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.7523 - val_loss: 0.4963 - val_accuracy: 0.7468\n",
      "Epoch 239/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4978 - accuracy: 0.7504 - val_loss: 0.5271 - val_accuracy: 0.7262\n",
      "Epoch 240/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4981 - accuracy: 0.7491 - val_loss: 0.4964 - val_accuracy: 0.7461\n",
      "Epoch 241/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.7505 - val_loss: 0.4904 - val_accuracy: 0.7535\n",
      "Epoch 242/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.7512 - val_loss: 0.4898 - val_accuracy: 0.7539\n",
      "Epoch 243/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4983 - accuracy: 0.7487 - val_loss: 0.4896 - val_accuracy: 0.7539\n",
      "Epoch 244/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4976 - accuracy: 0.7504 - val_loss: 0.4928 - val_accuracy: 0.7506\n",
      "Epoch 245/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4988 - accuracy: 0.7536 - val_loss: 0.4889 - val_accuracy: 0.7541\n",
      "Epoch 246/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.7519 - val_loss: 0.4920 - val_accuracy: 0.7513\n",
      "Epoch 247/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.7526 - val_loss: 0.4891 - val_accuracy: 0.7532\n",
      "Epoch 248/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4966 - accuracy: 0.7528 - val_loss: 0.4926 - val_accuracy: 0.7506\n",
      "Epoch 249/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4970 - accuracy: 0.7540 - val_loss: 0.4941 - val_accuracy: 0.7513\n",
      "Epoch 250/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4988 - accuracy: 0.7502 - val_loss: 0.5478 - val_accuracy: 0.7162\n",
      "Epoch 251/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4972 - accuracy: 0.7510 - val_loss: 0.4991 - val_accuracy: 0.7481\n",
      "Epoch 252/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4970 - accuracy: 0.7529 - val_loss: 0.4907 - val_accuracy: 0.7522\n",
      "Epoch 253/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4971 - accuracy: 0.7518 - val_loss: 0.4960 - val_accuracy: 0.7455\n",
      "Epoch 254/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4968 - accuracy: 0.7509 - val_loss: 0.5112 - val_accuracy: 0.7335\n",
      "Epoch 255/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4973 - accuracy: 0.7522 - val_loss: 0.5080 - val_accuracy: 0.7383\n",
      "Epoch 256/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4972 - accuracy: 0.7515 - val_loss: 0.4892 - val_accuracy: 0.7532\n",
      "Epoch 257/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4974 - accuracy: 0.7496 - val_loss: 0.5377 - val_accuracy: 0.7249\n",
      "Epoch 258/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4963 - accuracy: 0.7529 - val_loss: 0.4934 - val_accuracy: 0.7506\n",
      "Epoch 259/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4968 - accuracy: 0.7522 - val_loss: 0.4962 - val_accuracy: 0.7496\n",
      "Epoch 260/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4972 - accuracy: 0.7525 - val_loss: 0.4903 - val_accuracy: 0.7541\n",
      "Epoch 261/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4974 - accuracy: 0.7518 - val_loss: 0.4888 - val_accuracy: 0.7541\n",
      "Epoch 262/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4974 - accuracy: 0.7530 - val_loss: 0.4894 - val_accuracy: 0.7548\n",
      "Epoch 263/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4966 - accuracy: 0.7523 - val_loss: 0.5029 - val_accuracy: 0.7455\n",
      "Epoch 264/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4972 - accuracy: 0.7529 - val_loss: 0.4917 - val_accuracy: 0.7519\n",
      "Epoch 265/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4974 - accuracy: 0.7506 - val_loss: 0.4980 - val_accuracy: 0.7506\n",
      "Epoch 266/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4960 - accuracy: 0.7529 - val_loss: 0.5062 - val_accuracy: 0.7411\n",
      "Epoch 267/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4976 - accuracy: 0.7508 - val_loss: 0.5113 - val_accuracy: 0.7361\n",
      "Epoch 268/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4972 - accuracy: 0.7524 - val_loss: 0.4902 - val_accuracy: 0.7558\n",
      "Epoch 269/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4977 - accuracy: 0.7508 - val_loss: 0.5619 - val_accuracy: 0.7091\n",
      "Epoch 270/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4973 - accuracy: 0.7522 - val_loss: 0.4916 - val_accuracy: 0.7513\n",
      "Epoch 271/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4966 - accuracy: 0.7522 - val_loss: 0.4945 - val_accuracy: 0.7524\n",
      "Epoch 272/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4966 - accuracy: 0.7498 - val_loss: 0.4885 - val_accuracy: 0.7554\n",
      "Epoch 273/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4954 - accuracy: 0.7547 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
      "Epoch 274/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4963 - accuracy: 0.7528 - val_loss: 0.5092 - val_accuracy: 0.7407\n",
      "Epoch 275/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4972 - accuracy: 0.7495 - val_loss: 0.5106 - val_accuracy: 0.7374\n",
      "Epoch 276/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4974 - accuracy: 0.7519 - val_loss: 0.4874 - val_accuracy: 0.7550\n",
      "Epoch 277/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4962 - accuracy: 0.7538 - val_loss: 0.4887 - val_accuracy: 0.7535\n",
      "Epoch 278/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4966 - accuracy: 0.7505 - val_loss: 0.5204 - val_accuracy: 0.7312\n",
      "Epoch 279/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4955 - accuracy: 0.7540 - val_loss: 0.5258 - val_accuracy: 0.7279\n",
      "Epoch 280/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4961 - accuracy: 0.7552 - val_loss: 0.4961 - val_accuracy: 0.7513\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4960 - accuracy: 0.7528 - val_loss: 0.5004 - val_accuracy: 0.7476\n",
      "Epoch 282/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4960 - accuracy: 0.7555 - val_loss: 0.4865 - val_accuracy: 0.7567\n",
      "Epoch 283/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4967 - accuracy: 0.7540 - val_loss: 0.4880 - val_accuracy: 0.7535\n",
      "Epoch 284/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4964 - accuracy: 0.7521 - val_loss: 0.4856 - val_accuracy: 0.7576\n",
      "Epoch 285/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4956 - accuracy: 0.7540 - val_loss: 0.4918 - val_accuracy: 0.7532\n",
      "Epoch 286/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4968 - accuracy: 0.7534 - val_loss: 0.4870 - val_accuracy: 0.7554\n",
      "Epoch 287/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4961 - accuracy: 0.7525 - val_loss: 0.4935 - val_accuracy: 0.7474\n",
      "Epoch 288/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4958 - accuracy: 0.7529 - val_loss: 0.5024 - val_accuracy: 0.7457\n",
      "Epoch 289/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4956 - accuracy: 0.7522 - val_loss: 0.4852 - val_accuracy: 0.7535\n",
      "Epoch 290/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4958 - accuracy: 0.7518 - val_loss: 0.5101 - val_accuracy: 0.7346\n",
      "Epoch 291/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4958 - accuracy: 0.7510 - val_loss: 0.5032 - val_accuracy: 0.7411\n",
      "Epoch 292/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4967 - accuracy: 0.7521 - val_loss: 0.4972 - val_accuracy: 0.7463\n",
      "Epoch 293/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4953 - accuracy: 0.7556 - val_loss: 0.4847 - val_accuracy: 0.7563\n",
      "Epoch 294/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4959 - accuracy: 0.7528 - val_loss: 0.4849 - val_accuracy: 0.7556\n",
      "Epoch 295/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4952 - accuracy: 0.7551 - val_loss: 0.4860 - val_accuracy: 0.7554\n",
      "Epoch 296/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4951 - accuracy: 0.7531 - val_loss: 0.4959 - val_accuracy: 0.7511\n",
      "Epoch 297/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4946 - accuracy: 0.7512 - val_loss: 0.4923 - val_accuracy: 0.7485\n",
      "Epoch 298/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4959 - accuracy: 0.7535 - val_loss: 0.5210 - val_accuracy: 0.7284\n",
      "Epoch 299/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4942 - accuracy: 0.7548 - val_loss: 0.4883 - val_accuracy: 0.7548\n",
      "Epoch 300/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4966 - accuracy: 0.7525 - val_loss: 0.4977 - val_accuracy: 0.7468\n",
      "Epoch 301/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4955 - accuracy: 0.7521 - val_loss: 0.4850 - val_accuracy: 0.7580\n",
      "Epoch 302/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4950 - accuracy: 0.7547 - val_loss: 0.4852 - val_accuracy: 0.7576\n",
      "Epoch 303/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4949 - accuracy: 0.7535 - val_loss: 0.4903 - val_accuracy: 0.7532\n",
      "Epoch 304/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7532 - val_loss: 0.4851 - val_accuracy: 0.7574\n",
      "Epoch 305/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7534 - val_loss: 0.4901 - val_accuracy: 0.7537\n",
      "Epoch 306/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4954 - accuracy: 0.7528 - val_loss: 0.4839 - val_accuracy: 0.7561\n",
      "Epoch 307/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.7520 - val_loss: 0.5220 - val_accuracy: 0.7307\n",
      "Epoch 308/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4958 - accuracy: 0.7539 - val_loss: 0.4835 - val_accuracy: 0.7569\n",
      "Epoch 309/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4942 - accuracy: 0.7556 - val_loss: 0.4937 - val_accuracy: 0.7496\n",
      "Epoch 310/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4941 - accuracy: 0.7555 - val_loss: 0.4832 - val_accuracy: 0.7580\n",
      "Epoch 311/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4937 - accuracy: 0.7554 - val_loss: 0.4833 - val_accuracy: 0.7589\n",
      "Epoch 312/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4955 - accuracy: 0.7560 - val_loss: 0.4856 - val_accuracy: 0.7556\n",
      "Epoch 313/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4946 - accuracy: 0.7541 - val_loss: 0.4897 - val_accuracy: 0.7541\n",
      "Epoch 314/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4954 - accuracy: 0.7555 - val_loss: 0.6188 - val_accuracy: 0.6840\n",
      "Epoch 315/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4957 - accuracy: 0.7547 - val_loss: 0.4854 - val_accuracy: 0.7556\n",
      "Epoch 316/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4946 - accuracy: 0.7532 - val_loss: 0.4835 - val_accuracy: 0.7582\n",
      "Epoch 317/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4943 - accuracy: 0.7536 - val_loss: 0.6711 - val_accuracy: 0.6392\n",
      "Epoch 318/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4951 - accuracy: 0.7552 - val_loss: 0.4997 - val_accuracy: 0.7468\n",
      "Epoch 319/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4951 - accuracy: 0.7524 - val_loss: 0.4833 - val_accuracy: 0.7582\n",
      "Epoch 320/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4954 - accuracy: 0.7519 - val_loss: 0.5027 - val_accuracy: 0.7403\n",
      "Epoch 321/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4929 - accuracy: 0.7567 - val_loss: 0.4859 - val_accuracy: 0.7545\n",
      "Epoch 322/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4930 - accuracy: 0.7557 - val_loss: 0.4890 - val_accuracy: 0.7537\n",
      "Epoch 323/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4949 - accuracy: 0.7512 - val_loss: 0.5003 - val_accuracy: 0.7476\n",
      "Epoch 324/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4940 - accuracy: 0.7547 - val_loss: 0.4893 - val_accuracy: 0.7539\n",
      "Epoch 325/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4936 - accuracy: 0.7570 - val_loss: 0.4818 - val_accuracy: 0.7600\n",
      "Epoch 326/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4947 - accuracy: 0.7531 - val_loss: 0.5439 - val_accuracy: 0.7199\n",
      "Epoch 327/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4915 - accuracy: 0.7558 - val_loss: 0.4981 - val_accuracy: 0.7485\n",
      "Epoch 328/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4936 - accuracy: 0.7564 - val_loss: 0.4825 - val_accuracy: 0.7582\n",
      "Epoch 329/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4956 - accuracy: 0.7515 - val_loss: 0.4943 - val_accuracy: 0.7465\n",
      "Epoch 330/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4931 - accuracy: 0.7554 - val_loss: 0.4821 - val_accuracy: 0.7597\n",
      "Epoch 331/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4939 - accuracy: 0.7541 - val_loss: 0.4989 - val_accuracy: 0.7474\n",
      "Epoch 332/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4932 - accuracy: 0.7550 - val_loss: 0.4863 - val_accuracy: 0.7515\n",
      "Epoch 333/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4946 - accuracy: 0.7528 - val_loss: 0.4808 - val_accuracy: 0.7582\n",
      "Epoch 334/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4933 - accuracy: 0.7545 - val_loss: 0.4806 - val_accuracy: 0.7613\n",
      "Epoch 335/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4932 - accuracy: 0.7556 - val_loss: 0.5293 - val_accuracy: 0.7323\n",
      "Epoch 336/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4931 - accuracy: 0.7536 - val_loss: 0.4864 - val_accuracy: 0.7541\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4949 - accuracy: 0.7536 - val_loss: 0.4850 - val_accuracy: 0.7567\n",
      "Epoch 338/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4929 - accuracy: 0.7540 - val_loss: 0.4918 - val_accuracy: 0.7494\n",
      "Epoch 339/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4938 - accuracy: 0.7544 - val_loss: 0.4838 - val_accuracy: 0.7571\n",
      "Epoch 340/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4927 - accuracy: 0.7557 - val_loss: 0.4805 - val_accuracy: 0.7604\n",
      "Epoch 341/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4938 - accuracy: 0.7535 - val_loss: 0.4813 - val_accuracy: 0.7634\n",
      "Epoch 342/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4920 - accuracy: 0.7573 - val_loss: 0.5382 - val_accuracy: 0.7229\n",
      "Epoch 343/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4936 - accuracy: 0.7548 - val_loss: 0.5183 - val_accuracy: 0.7357\n",
      "Epoch 344/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4941 - accuracy: 0.7553 - val_loss: 0.5327 - val_accuracy: 0.7281\n",
      "Epoch 345/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4933 - accuracy: 0.7547 - val_loss: 0.4923 - val_accuracy: 0.7522\n",
      "Epoch 346/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4929 - accuracy: 0.7552 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 347/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4932 - accuracy: 0.7551 - val_loss: 0.5147 - val_accuracy: 0.7338\n",
      "Epoch 348/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4948 - accuracy: 0.7543 - val_loss: 0.5088 - val_accuracy: 0.7374\n",
      "Epoch 349/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4933 - accuracy: 0.7571 - val_loss: 0.4807 - val_accuracy: 0.7584\n",
      "Epoch 350/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.7541 - val_loss: 0.5790 - val_accuracy: 0.6996\n",
      "Epoch 351/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4932 - accuracy: 0.7556 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 352/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.7563 - val_loss: 0.4840 - val_accuracy: 0.7578\n",
      "Epoch 353/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4912 - accuracy: 0.7553 - val_loss: 0.4806 - val_accuracy: 0.7634\n",
      "Epoch 354/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4933 - accuracy: 0.7531 - val_loss: 0.5065 - val_accuracy: 0.7392\n",
      "Epoch 355/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4925 - accuracy: 0.7556 - val_loss: 0.4792 - val_accuracy: 0.7608\n",
      "Epoch 356/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4925 - accuracy: 0.7552 - val_loss: 0.4988 - val_accuracy: 0.7459\n",
      "Epoch 357/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4917 - accuracy: 0.7573 - val_loss: 0.5009 - val_accuracy: 0.7439\n",
      "Epoch 358/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4923 - accuracy: 0.7560 - val_loss: 0.6699 - val_accuracy: 0.6424\n",
      "Epoch 359/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4923 - accuracy: 0.7553 - val_loss: 0.5052 - val_accuracy: 0.7420\n",
      "Epoch 360/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4925 - accuracy: 0.7554 - val_loss: 0.5096 - val_accuracy: 0.7411\n",
      "Epoch 361/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4945 - accuracy: 0.7538 - val_loss: 0.5255 - val_accuracy: 0.7355\n",
      "Epoch 362/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4923 - accuracy: 0.7574 - val_loss: 0.4783 - val_accuracy: 0.7630\n",
      "Epoch 363/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4926 - accuracy: 0.7555 - val_loss: 0.5175 - val_accuracy: 0.7353\n",
      "Epoch 364/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4925 - accuracy: 0.7567 - val_loss: 0.5294 - val_accuracy: 0.7316\n",
      "Epoch 365/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4918 - accuracy: 0.7556 - val_loss: 0.5013 - val_accuracy: 0.7426\n",
      "Epoch 366/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4916 - accuracy: 0.7556 - val_loss: 0.5808 - val_accuracy: 0.6981\n",
      "Epoch 367/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4922 - accuracy: 0.7547 - val_loss: 0.4812 - val_accuracy: 0.7593\n",
      "Epoch 368/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4921 - accuracy: 0.7518 - val_loss: 0.4827 - val_accuracy: 0.7558\n",
      "Epoch 369/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4922 - accuracy: 0.7556 - val_loss: 0.4864 - val_accuracy: 0.7541\n",
      "Epoch 370/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4926 - accuracy: 0.7557 - val_loss: 0.5094 - val_accuracy: 0.7381\n",
      "Epoch 371/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4929 - accuracy: 0.7540 - val_loss: 0.4881 - val_accuracy: 0.7526\n",
      "Epoch 372/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4928 - accuracy: 0.7564 - val_loss: 0.5186 - val_accuracy: 0.7351\n",
      "Epoch 373/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4934 - accuracy: 0.7540 - val_loss: 0.4876 - val_accuracy: 0.7548\n",
      "Epoch 374/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4922 - accuracy: 0.7559 - val_loss: 0.4867 - val_accuracy: 0.7526\n",
      "Epoch 375/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4901 - accuracy: 0.7576 - val_loss: 0.4770 - val_accuracy: 0.7630\n",
      "Epoch 376/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4911 - accuracy: 0.7544 - val_loss: 0.4805 - val_accuracy: 0.7587\n",
      "Epoch 377/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4907 - accuracy: 0.7547 - val_loss: 0.5670 - val_accuracy: 0.7061\n",
      "Epoch 378/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4947 - accuracy: 0.7523 - val_loss: 0.4779 - val_accuracy: 0.7595\n",
      "Epoch 379/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4917 - accuracy: 0.7560 - val_loss: 0.4860 - val_accuracy: 0.7565\n",
      "Epoch 380/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4903 - accuracy: 0.7569 - val_loss: 0.4801 - val_accuracy: 0.7617\n",
      "Epoch 381/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4909 - accuracy: 0.7545 - val_loss: 0.4955 - val_accuracy: 0.7455\n",
      "Epoch 382/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4909 - accuracy: 0.7576 - val_loss: 0.4957 - val_accuracy: 0.7461\n",
      "Epoch 383/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4921 - accuracy: 0.7574 - val_loss: 0.5069 - val_accuracy: 0.7407\n",
      "Epoch 384/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4913 - accuracy: 0.7558 - val_loss: 0.4776 - val_accuracy: 0.7636\n",
      "Epoch 385/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4913 - accuracy: 0.7573 - val_loss: 0.5004 - val_accuracy: 0.7463\n",
      "Epoch 386/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4915 - accuracy: 0.7539 - val_loss: 0.5307 - val_accuracy: 0.7310\n",
      "Epoch 387/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4915 - accuracy: 0.7534 - val_loss: 0.4768 - val_accuracy: 0.7669\n",
      "Epoch 388/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4914 - accuracy: 0.7565 - val_loss: 0.4787 - val_accuracy: 0.7639\n",
      "Epoch 389/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4897 - accuracy: 0.7587 - val_loss: 0.4767 - val_accuracy: 0.7628\n",
      "Epoch 390/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4893 - accuracy: 0.7612 - val_loss: 0.4807 - val_accuracy: 0.7574\n",
      "Epoch 391/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4898 - accuracy: 0.7581 - val_loss: 0.4918 - val_accuracy: 0.7511\n",
      "Epoch 392/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4922 - accuracy: 0.7549 - val_loss: 0.4931 - val_accuracy: 0.7491\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4888 - accuracy: 0.7559 - val_loss: 0.4769 - val_accuracy: 0.7652\n",
      "Epoch 394/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4919 - accuracy: 0.7573 - val_loss: 0.4796 - val_accuracy: 0.7619\n",
      "Epoch 395/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4914 - accuracy: 0.7552 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 396/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4911 - accuracy: 0.7571 - val_loss: 0.4757 - val_accuracy: 0.7643\n",
      "Epoch 397/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4893 - accuracy: 0.7564 - val_loss: 0.4811 - val_accuracy: 0.7580\n",
      "Epoch 398/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4914 - accuracy: 0.7564 - val_loss: 0.4752 - val_accuracy: 0.7632\n",
      "Epoch 399/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4904 - accuracy: 0.7559 - val_loss: 0.5029 - val_accuracy: 0.7431\n",
      "Epoch 400/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4902 - accuracy: 0.7596 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 401/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4916 - accuracy: 0.7563 - val_loss: 0.4787 - val_accuracy: 0.7600\n",
      "Epoch 402/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4903 - accuracy: 0.7580 - val_loss: 0.5126 - val_accuracy: 0.7398\n",
      "Epoch 403/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4923 - accuracy: 0.7562 - val_loss: 0.4981 - val_accuracy: 0.7448\n",
      "Epoch 404/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4901 - accuracy: 0.7561 - val_loss: 0.4837 - val_accuracy: 0.7591\n",
      "Epoch 405/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4903 - accuracy: 0.7569 - val_loss: 0.5010 - val_accuracy: 0.7463\n",
      "Epoch 406/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4903 - accuracy: 0.7559 - val_loss: 0.4808 - val_accuracy: 0.7571\n",
      "Epoch 407/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4907 - accuracy: 0.7575 - val_loss: 0.4773 - val_accuracy: 0.7641\n",
      "Epoch 408/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4916 - accuracy: 0.7567 - val_loss: 0.4786 - val_accuracy: 0.7600\n",
      "Epoch 409/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.7582 - val_loss: 0.4915 - val_accuracy: 0.7515\n",
      "Epoch 410/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4896 - accuracy: 0.7554 - val_loss: 0.4804 - val_accuracy: 0.7584\n",
      "Epoch 411/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4900 - accuracy: 0.7586 - val_loss: 0.4750 - val_accuracy: 0.7615\n",
      "Epoch 412/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4904 - accuracy: 0.7602 - val_loss: 0.4746 - val_accuracy: 0.7665\n",
      "Epoch 413/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4898 - accuracy: 0.7559 - val_loss: 0.6284 - val_accuracy: 0.6825\n",
      "Epoch 414/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4896 - accuracy: 0.7575 - val_loss: 0.4741 - val_accuracy: 0.7634\n",
      "Epoch 415/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4883 - accuracy: 0.7589 - val_loss: 0.5263 - val_accuracy: 0.7348\n",
      "Epoch 416/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4915 - accuracy: 0.7554 - val_loss: 0.5512 - val_accuracy: 0.7132\n",
      "Epoch 417/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4894 - accuracy: 0.7584 - val_loss: 0.4735 - val_accuracy: 0.7630\n",
      "Epoch 418/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4876 - accuracy: 0.7562 - val_loss: 0.5741 - val_accuracy: 0.7026\n",
      "Epoch 419/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4902 - accuracy: 0.7557 - val_loss: 0.4772 - val_accuracy: 0.7645\n",
      "Epoch 420/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.7573 - val_loss: 0.5316 - val_accuracy: 0.7277\n",
      "Epoch 421/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4894 - accuracy: 0.7568 - val_loss: 0.4781 - val_accuracy: 0.7621\n",
      "Epoch 422/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.7577 - val_loss: 0.4730 - val_accuracy: 0.7628\n",
      "Epoch 423/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4900 - accuracy: 0.7567 - val_loss: 0.5115 - val_accuracy: 0.7364\n",
      "Epoch 424/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4886 - accuracy: 0.7593 - val_loss: 0.4729 - val_accuracy: 0.7667\n",
      "Epoch 425/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4901 - accuracy: 0.7584 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 426/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4882 - accuracy: 0.7610 - val_loss: 0.5044 - val_accuracy: 0.7426\n",
      "Epoch 427/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4884 - accuracy: 0.7568 - val_loss: 0.7227 - val_accuracy: 0.6165\n",
      "Epoch 428/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4888 - accuracy: 0.7582 - val_loss: 0.5009 - val_accuracy: 0.7424\n",
      "Epoch 429/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4886 - accuracy: 0.7573 - val_loss: 0.4786 - val_accuracy: 0.7597\n",
      "Epoch 430/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7594 - val_loss: 0.5323 - val_accuracy: 0.7310\n",
      "Epoch 431/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7566 - val_loss: 0.4794 - val_accuracy: 0.7608\n",
      "Epoch 432/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.7560 - val_loss: 0.5013 - val_accuracy: 0.7444\n",
      "Epoch 433/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4911 - accuracy: 0.7553 - val_loss: 0.4954 - val_accuracy: 0.7470\n",
      "Epoch 434/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4898 - accuracy: 0.7545 - val_loss: 0.4721 - val_accuracy: 0.7652\n",
      "Epoch 435/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4924 - accuracy: 0.7558 - val_loss: 0.4866 - val_accuracy: 0.7532\n",
      "Epoch 436/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.7585 - val_loss: 0.4771 - val_accuracy: 0.7654\n",
      "Epoch 437/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.7608 - val_loss: 0.5434 - val_accuracy: 0.7186\n",
      "Epoch 438/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7601 - val_loss: 0.4807 - val_accuracy: 0.7567\n",
      "Epoch 439/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.7581 - val_loss: 0.6368 - val_accuracy: 0.6623\n",
      "Epoch 440/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.7571 - val_loss: 0.4872 - val_accuracy: 0.7545\n",
      "Epoch 441/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.7559 - val_loss: 0.4828 - val_accuracy: 0.7554\n",
      "Epoch 442/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.7584 - val_loss: 0.4803 - val_accuracy: 0.7595\n",
      "Epoch 443/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7565 - val_loss: 0.4837 - val_accuracy: 0.7543\n",
      "Epoch 444/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.7611 - val_loss: 0.6093 - val_accuracy: 0.6807\n",
      "Epoch 445/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.7616 - val_loss: 0.5260 - val_accuracy: 0.7329\n",
      "Epoch 446/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.7567 - val_loss: 0.4758 - val_accuracy: 0.7654\n",
      "Epoch 447/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4896 - accuracy: 0.7568 - val_loss: 0.5120 - val_accuracy: 0.7383\n",
      "Epoch 448/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7590 - val_loss: 0.4832 - val_accuracy: 0.7569\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7601 - val_loss: 0.4977 - val_accuracy: 0.7463\n",
      "Epoch 450/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.7582 - val_loss: 0.4713 - val_accuracy: 0.7647\n",
      "Epoch 451/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.7572 - val_loss: 0.4718 - val_accuracy: 0.7669\n",
      "Epoch 452/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.7585 - val_loss: 0.4733 - val_accuracy: 0.7677\n",
      "Epoch 453/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4868 - accuracy: 0.7590 - val_loss: 0.4710 - val_accuracy: 0.7645\n",
      "Epoch 454/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7575 - val_loss: 0.4828 - val_accuracy: 0.7545\n",
      "Epoch 455/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7580 - val_loss: 0.4789 - val_accuracy: 0.7591\n",
      "Epoch 456/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7595 - val_loss: 0.4843 - val_accuracy: 0.7574\n",
      "Epoch 457/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7551 - val_loss: 0.6920 - val_accuracy: 0.6294\n",
      "Epoch 458/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.7589 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 459/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4868 - accuracy: 0.7596 - val_loss: 0.4771 - val_accuracy: 0.7593\n",
      "Epoch 460/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.7593 - val_loss: 0.4740 - val_accuracy: 0.7623\n",
      "Epoch 461/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4880 - accuracy: 0.7582 - val_loss: 0.5289 - val_accuracy: 0.7318\n",
      "Epoch 462/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4873 - accuracy: 0.7581 - val_loss: 0.4876 - val_accuracy: 0.7517\n",
      "Epoch 463/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7603 - val_loss: 0.4874 - val_accuracy: 0.7524\n",
      "Epoch 464/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7597 - val_loss: 0.4695 - val_accuracy: 0.7647\n",
      "Epoch 465/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7591 - val_loss: 0.4690 - val_accuracy: 0.7690\n",
      "Epoch 466/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4880 - accuracy: 0.7579 - val_loss: 0.5036 - val_accuracy: 0.7418\n",
      "Epoch 467/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7593 - val_loss: 0.4737 - val_accuracy: 0.7662\n",
      "Epoch 468/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.7600 - val_loss: 0.5520 - val_accuracy: 0.7152\n",
      "Epoch 469/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7573 - val_loss: 0.4793 - val_accuracy: 0.7623\n",
      "Epoch 470/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4869 - accuracy: 0.7601 - val_loss: 0.5265 - val_accuracy: 0.7247\n",
      "Epoch 471/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7590 - val_loss: 0.5168 - val_accuracy: 0.7368\n",
      "Epoch 472/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.7584 - val_loss: 0.4775 - val_accuracy: 0.7587\n",
      "Epoch 473/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7594 - val_loss: 0.5467 - val_accuracy: 0.7175\n",
      "Epoch 474/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4861 - accuracy: 0.7605 - val_loss: 0.5134 - val_accuracy: 0.7381\n",
      "Epoch 475/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.7573 - val_loss: 0.5003 - val_accuracy: 0.7420\n",
      "Epoch 476/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.7590 - val_loss: 0.6999 - val_accuracy: 0.6284\n",
      "Epoch 477/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7584 - val_loss: 0.5217 - val_accuracy: 0.7340\n",
      "Epoch 478/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7590 - val_loss: 0.5853 - val_accuracy: 0.7002\n",
      "Epoch 479/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4868 - accuracy: 0.7607 - val_loss: 0.5526 - val_accuracy: 0.7136\n",
      "Epoch 480/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7608 - val_loss: 0.4833 - val_accuracy: 0.7548\n",
      "Epoch 481/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4861 - accuracy: 0.7622 - val_loss: 0.5142 - val_accuracy: 0.7325\n",
      "Epoch 482/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7602 - val_loss: 0.4685 - val_accuracy: 0.7695\n",
      "Epoch 483/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4878 - accuracy: 0.7573 - val_loss: 0.5252 - val_accuracy: 0.7340\n",
      "Epoch 484/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7575 - val_loss: 0.5841 - val_accuracy: 0.6937\n",
      "Epoch 485/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7614 - val_loss: 0.4679 - val_accuracy: 0.7673\n",
      "Epoch 486/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4876 - accuracy: 0.7575 - val_loss: 0.5471 - val_accuracy: 0.7154\n",
      "Epoch 487/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4851 - accuracy: 0.7596 - val_loss: 0.4760 - val_accuracy: 0.7621\n",
      "Epoch 488/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4872 - accuracy: 0.7614 - val_loss: 0.4673 - val_accuracy: 0.7703\n",
      "Epoch 489/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4874 - accuracy: 0.7578 - val_loss: 0.4688 - val_accuracy: 0.7708\n",
      "Epoch 490/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4868 - accuracy: 0.7604 - val_loss: 0.4883 - val_accuracy: 0.7522\n",
      "Epoch 491/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4856 - accuracy: 0.7601 - val_loss: 0.4972 - val_accuracy: 0.7468\n",
      "Epoch 492/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4871 - accuracy: 0.7583 - val_loss: 0.4716 - val_accuracy: 0.7639\n",
      "Epoch 493/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4857 - accuracy: 0.7593 - val_loss: 0.4801 - val_accuracy: 0.7593\n",
      "Epoch 494/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4858 - accuracy: 0.7567 - val_loss: 0.4804 - val_accuracy: 0.7602\n",
      "Epoch 495/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4862 - accuracy: 0.7589 - val_loss: 0.4952 - val_accuracy: 0.7487\n",
      "Epoch 496/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4864 - accuracy: 0.7613 - val_loss: 0.5322 - val_accuracy: 0.7294\n",
      "Epoch 497/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4878 - accuracy: 0.7588 - val_loss: 0.4735 - val_accuracy: 0.7610\n",
      "Epoch 498/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7568 - val_loss: 0.5665 - val_accuracy: 0.7061\n",
      "Epoch 499/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7574 - val_loss: 0.5603 - val_accuracy: 0.7108\n",
      "Epoch 500/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7603 - val_loss: 0.5140 - val_accuracy: 0.7405\n",
      "Epoch 501/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4873 - accuracy: 0.7595 - val_loss: 0.4881 - val_accuracy: 0.7537\n",
      "Epoch 502/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.7619 - val_loss: 0.4668 - val_accuracy: 0.7719\n",
      "Epoch 503/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.7596 - val_loss: 0.5069 - val_accuracy: 0.7439\n",
      "Epoch 504/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7598 - val_loss: 0.4671 - val_accuracy: 0.7706\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7595 - val_loss: 0.4756 - val_accuracy: 0.7604\n",
      "Epoch 506/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7593 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 507/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7607 - val_loss: 0.4714 - val_accuracy: 0.7708\n",
      "Epoch 508/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7594 - val_loss: 0.4823 - val_accuracy: 0.7584\n",
      "Epoch 509/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4867 - accuracy: 0.7585 - val_loss: 0.4673 - val_accuracy: 0.7732\n",
      "Epoch 510/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.7591 - val_loss: 0.4716 - val_accuracy: 0.7682\n",
      "Epoch 511/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4830 - accuracy: 0.7619 - val_loss: 0.4898 - val_accuracy: 0.7519\n",
      "Epoch 512/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7596 - val_loss: 0.4679 - val_accuracy: 0.7708\n",
      "Epoch 513/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7600 - val_loss: 0.5136 - val_accuracy: 0.7411\n",
      "Epoch 514/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4847 - accuracy: 0.7601 - val_loss: 0.6164 - val_accuracy: 0.6745\n",
      "Epoch 515/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.7599 - val_loss: 0.4648 - val_accuracy: 0.7723\n",
      "Epoch 516/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4872 - accuracy: 0.7565 - val_loss: 0.4808 - val_accuracy: 0.7608\n",
      "Epoch 517/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7610 - val_loss: 0.4669 - val_accuracy: 0.7719\n",
      "Epoch 518/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.7616 - val_loss: 0.4642 - val_accuracy: 0.7697\n",
      "Epoch 519/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7628 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 520/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7600 - val_loss: 0.5448 - val_accuracy: 0.7165\n",
      "Epoch 521/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7597 - val_loss: 0.4680 - val_accuracy: 0.7675\n",
      "Epoch 522/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7587 - val_loss: 0.4934 - val_accuracy: 0.7496\n",
      "Epoch 523/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4848 - accuracy: 0.7595 - val_loss: 0.4665 - val_accuracy: 0.7669\n",
      "Epoch 524/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4812 - accuracy: 0.7605 - val_loss: 0.4713 - val_accuracy: 0.7652\n",
      "Epoch 525/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4830 - accuracy: 0.7608 - val_loss: 0.5075 - val_accuracy: 0.7457\n",
      "Epoch 526/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4824 - accuracy: 0.7614 - val_loss: 0.4635 - val_accuracy: 0.7699\n",
      "Epoch 527/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7595 - val_loss: 0.4753 - val_accuracy: 0.7628\n",
      "Epoch 528/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7588 - val_loss: 0.4840 - val_accuracy: 0.7539\n",
      "Epoch 529/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7588 - val_loss: 0.4641 - val_accuracy: 0.7721\n",
      "Epoch 530/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.7591 - val_loss: 0.4977 - val_accuracy: 0.7498\n",
      "Epoch 531/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.7635 - val_loss: 0.4652 - val_accuracy: 0.7684\n",
      "Epoch 532/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7613 - val_loss: 0.5087 - val_accuracy: 0.7426\n",
      "Epoch 533/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.7594 - val_loss: 0.4826 - val_accuracy: 0.7561\n",
      "Epoch 534/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7623 - val_loss: 0.5641 - val_accuracy: 0.7106\n",
      "Epoch 535/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7602 - val_loss: 0.4702 - val_accuracy: 0.7619\n",
      "Epoch 536/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7610 - val_loss: 0.4856 - val_accuracy: 0.7548\n",
      "Epoch 537/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.7630 - val_loss: 0.4722 - val_accuracy: 0.7613\n",
      "Epoch 538/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7596 - val_loss: 0.5223 - val_accuracy: 0.7377\n",
      "Epoch 539/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4814 - accuracy: 0.7644 - val_loss: 0.4643 - val_accuracy: 0.7760\n",
      "Epoch 540/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.7643 - val_loss: 0.4728 - val_accuracy: 0.7617\n",
      "Epoch 541/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4826 - accuracy: 0.7617 - val_loss: 0.4668 - val_accuracy: 0.7740\n",
      "Epoch 542/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7612 - val_loss: 0.5468 - val_accuracy: 0.7216\n",
      "Epoch 543/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.7611 - val_loss: 0.4625 - val_accuracy: 0.7708\n",
      "Epoch 544/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7600 - val_loss: 0.4785 - val_accuracy: 0.7587\n",
      "Epoch 545/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4826 - accuracy: 0.7612 - val_loss: 0.4642 - val_accuracy: 0.7749\n",
      "Epoch 546/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7626 - val_loss: 0.4892 - val_accuracy: 0.7494\n",
      "Epoch 547/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.7622 - val_loss: 0.4898 - val_accuracy: 0.7498\n",
      "Epoch 548/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7602 - val_loss: 0.4641 - val_accuracy: 0.7686\n",
      "Epoch 549/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4816 - accuracy: 0.7641 - val_loss: 0.4617 - val_accuracy: 0.7716\n",
      "Epoch 550/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4803 - accuracy: 0.7629 - val_loss: 0.5543 - val_accuracy: 0.7134\n",
      "Epoch 551/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4822 - accuracy: 0.7629 - val_loss: 0.4685 - val_accuracy: 0.7699\n",
      "Epoch 552/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7611 - val_loss: 0.4842 - val_accuracy: 0.7552\n",
      "Epoch 553/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.7577 - val_loss: 0.5401 - val_accuracy: 0.7242\n",
      "Epoch 554/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7620 - val_loss: 0.5049 - val_accuracy: 0.7465\n",
      "Epoch 555/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.7607 - val_loss: 0.4879 - val_accuracy: 0.7498\n",
      "Epoch 556/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7615 - val_loss: 0.5969 - val_accuracy: 0.6918\n",
      "Epoch 557/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7581 - val_loss: 0.5656 - val_accuracy: 0.7037\n",
      "Epoch 558/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4841 - accuracy: 0.7611 - val_loss: 0.4664 - val_accuracy: 0.7654\n",
      "Epoch 559/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4814 - accuracy: 0.7628 - val_loss: 0.5688 - val_accuracy: 0.7065\n",
      "Epoch 560/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4813 - accuracy: 0.7635 - val_loss: 0.5047 - val_accuracy: 0.7470\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.7624 - val_loss: 0.4611 - val_accuracy: 0.7758\n",
      "Epoch 562/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.7643 - val_loss: 0.4619 - val_accuracy: 0.7701\n",
      "Epoch 563/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.7617 - val_loss: 0.6357 - val_accuracy: 0.6929\n",
      "Epoch 564/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4813 - accuracy: 0.7622 - val_loss: 0.4652 - val_accuracy: 0.7755\n",
      "Epoch 565/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7588 - val_loss: 0.6343 - val_accuracy: 0.6881\n",
      "Epoch 566/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.7641 - val_loss: 0.4671 - val_accuracy: 0.7699\n",
      "Epoch 567/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.7610 - val_loss: 0.5252 - val_accuracy: 0.7338\n",
      "Epoch 568/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4823 - accuracy: 0.7613 - val_loss: 0.6695 - val_accuracy: 0.6481\n",
      "Epoch 569/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7648 - val_loss: 0.4628 - val_accuracy: 0.7758\n",
      "Epoch 570/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4810 - accuracy: 0.7652 - val_loss: 0.4824 - val_accuracy: 0.7528\n",
      "Epoch 571/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4830 - accuracy: 0.7614 - val_loss: 0.5660 - val_accuracy: 0.7095\n",
      "Epoch 572/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4839 - accuracy: 0.7583 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 573/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4810 - accuracy: 0.7608 - val_loss: 0.4759 - val_accuracy: 0.7597\n",
      "Epoch 574/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4808 - accuracy: 0.7611 - val_loss: 0.4631 - val_accuracy: 0.7745\n",
      "Epoch 575/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4813 - accuracy: 0.7615 - val_loss: 0.8890 - val_accuracy: 0.5502\n",
      "Epoch 576/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4836 - accuracy: 0.7606 - val_loss: 0.6190 - val_accuracy: 0.6734\n",
      "Epoch 577/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4822 - accuracy: 0.7614 - val_loss: 0.4737 - val_accuracy: 0.7643\n",
      "Epoch 578/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4809 - accuracy: 0.7609 - val_loss: 0.5046 - val_accuracy: 0.7487\n",
      "Epoch 579/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4811 - accuracy: 0.7633 - val_loss: 0.5142 - val_accuracy: 0.7348\n",
      "Epoch 580/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4819 - accuracy: 0.7618 - val_loss: 0.4715 - val_accuracy: 0.7649\n",
      "Epoch 581/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4836 - accuracy: 0.7588 - val_loss: 0.4722 - val_accuracy: 0.7634\n",
      "Epoch 582/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4793 - accuracy: 0.7627 - val_loss: 0.5976 - val_accuracy: 0.6907\n",
      "Epoch 583/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4810 - accuracy: 0.7616 - val_loss: 0.4642 - val_accuracy: 0.7753\n",
      "Epoch 584/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4812 - accuracy: 0.7609 - val_loss: 0.4598 - val_accuracy: 0.7738\n",
      "Epoch 585/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4825 - accuracy: 0.7622 - val_loss: 0.4628 - val_accuracy: 0.7671\n",
      "Epoch 586/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4793 - accuracy: 0.7649 - val_loss: 0.6863 - val_accuracy: 0.6396\n",
      "Epoch 587/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4816 - accuracy: 0.7640 - val_loss: 0.4582 - val_accuracy: 0.7736\n",
      "Epoch 588/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4819 - accuracy: 0.7631 - val_loss: 0.4589 - val_accuracy: 0.7758\n",
      "Epoch 589/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4801 - accuracy: 0.7614 - val_loss: 0.4789 - val_accuracy: 0.7584\n",
      "Epoch 590/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4822 - accuracy: 0.7642 - val_loss: 0.4591 - val_accuracy: 0.7762\n",
      "Epoch 591/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4812 - accuracy: 0.7624 - val_loss: 0.4845 - val_accuracy: 0.7556\n",
      "Epoch 592/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4819 - accuracy: 0.7607 - val_loss: 0.5582 - val_accuracy: 0.7149\n",
      "Epoch 593/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.4594 - val_accuracy: 0.7790\n",
      "Epoch 594/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4849 - accuracy: 0.7594 - val_loss: 0.4608 - val_accuracy: 0.7799\n",
      "Epoch 595/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4802 - accuracy: 0.7616 - val_loss: 0.4611 - val_accuracy: 0.7703\n",
      "Epoch 596/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4804 - accuracy: 0.7628 - val_loss: 0.4578 - val_accuracy: 0.7771\n",
      "Epoch 597/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4810 - accuracy: 0.7636 - val_loss: 0.7150 - val_accuracy: 0.6212\n",
      "Epoch 598/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4790 - accuracy: 0.7643 - val_loss: 0.4584 - val_accuracy: 0.7729\n",
      "Epoch 599/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4824 - accuracy: 0.7626 - val_loss: 0.4595 - val_accuracy: 0.7747\n",
      "Epoch 600/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4820 - accuracy: 0.7613 - val_loss: 0.8244 - val_accuracy: 0.5686\n",
      "Epoch 601/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4814 - accuracy: 0.7645 - val_loss: 0.4637 - val_accuracy: 0.7688\n",
      "Epoch 602/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4811 - accuracy: 0.7606 - val_loss: 0.4893 - val_accuracy: 0.7478\n",
      "Epoch 603/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4817 - accuracy: 0.7611 - val_loss: 0.4864 - val_accuracy: 0.7543\n",
      "Epoch 604/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4821 - accuracy: 0.7626 - val_loss: 0.5498 - val_accuracy: 0.7160\n",
      "Epoch 605/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4820 - accuracy: 0.7614 - val_loss: 0.4784 - val_accuracy: 0.7548\n",
      "Epoch 606/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4800 - accuracy: 0.7641 - val_loss: 0.5634 - val_accuracy: 0.7106\n",
      "Epoch 607/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4817 - accuracy: 0.7637 - val_loss: 0.4999 - val_accuracy: 0.7420\n",
      "Epoch 608/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4809 - accuracy: 0.7626 - val_loss: 0.5367 - val_accuracy: 0.7214\n",
      "Epoch 609/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4824 - accuracy: 0.7618 - val_loss: 0.4594 - val_accuracy: 0.7775\n",
      "Epoch 610/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4802 - accuracy: 0.7628 - val_loss: 0.4946 - val_accuracy: 0.7513\n",
      "Epoch 611/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4797 - accuracy: 0.7636 - val_loss: 0.5283 - val_accuracy: 0.7245\n",
      "Epoch 612/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4805 - accuracy: 0.7648 - val_loss: 0.5097 - val_accuracy: 0.7346\n",
      "Epoch 613/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4820 - accuracy: 0.7630 - val_loss: 0.5181 - val_accuracy: 0.7387\n",
      "Epoch 614/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4822 - accuracy: 0.7610 - val_loss: 0.4574 - val_accuracy: 0.7738\n",
      "Epoch 615/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4799 - accuracy: 0.7623 - val_loss: 0.4585 - val_accuracy: 0.7745\n",
      "Epoch 616/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4772 - accuracy: 0.7660 - val_loss: 0.5495 - val_accuracy: 0.7162\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4802 - accuracy: 0.7654 - val_loss: 0.4651 - val_accuracy: 0.7649\n",
      "Epoch 618/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4809 - accuracy: 0.7634 - val_loss: 0.4977 - val_accuracy: 0.7452\n",
      "Epoch 619/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4803 - accuracy: 0.7619 - val_loss: 0.4579 - val_accuracy: 0.7738\n",
      "Epoch 620/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4806 - accuracy: 0.7661 - val_loss: 0.5343 - val_accuracy: 0.7268\n",
      "Epoch 621/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4791 - accuracy: 0.7648 - val_loss: 0.4568 - val_accuracy: 0.7775\n",
      "Epoch 622/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4772 - accuracy: 0.7654 - val_loss: 0.4734 - val_accuracy: 0.7632\n",
      "Epoch 623/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.7611 - val_loss: 0.4563 - val_accuracy: 0.7816\n",
      "Epoch 624/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4806 - accuracy: 0.7625 - val_loss: 0.4560 - val_accuracy: 0.7771\n",
      "Epoch 625/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4809 - accuracy: 0.7658 - val_loss: 0.4703 - val_accuracy: 0.7610\n",
      "Epoch 626/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4776 - accuracy: 0.7637 - val_loss: 0.4688 - val_accuracy: 0.7686\n",
      "Epoch 627/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4772 - accuracy: 0.7648 - val_loss: 0.5215 - val_accuracy: 0.7364\n",
      "Epoch 628/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4806 - accuracy: 0.7648 - val_loss: 0.4877 - val_accuracy: 0.7580\n",
      "Epoch 629/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4788 - accuracy: 0.7627 - val_loss: 0.4584 - val_accuracy: 0.7732\n",
      "Epoch 630/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4777 - accuracy: 0.7662 - val_loss: 0.5189 - val_accuracy: 0.7307\n",
      "Epoch 631/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4838 - accuracy: 0.7602 - val_loss: 0.4641 - val_accuracy: 0.7719\n",
      "Epoch 632/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4783 - accuracy: 0.7648 - val_loss: 0.5290 - val_accuracy: 0.7342\n",
      "Epoch 633/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4777 - accuracy: 0.7649 - val_loss: 0.6831 - val_accuracy: 0.6786\n",
      "Epoch 634/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4826 - accuracy: 0.7613 - val_loss: 0.6498 - val_accuracy: 0.6786\n",
      "Epoch 635/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4816 - accuracy: 0.7620 - val_loss: 0.5059 - val_accuracy: 0.7455\n",
      "Epoch 636/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4813 - accuracy: 0.7648 - val_loss: 0.5861 - val_accuracy: 0.6972\n",
      "Epoch 637/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4801 - accuracy: 0.7615 - val_loss: 0.4572 - val_accuracy: 0.7725\n",
      "Epoch 638/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4794 - accuracy: 0.7642 - val_loss: 0.5161 - val_accuracy: 0.7338\n",
      "Epoch 639/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4797 - accuracy: 0.7649 - val_loss: 0.4757 - val_accuracy: 0.7626\n",
      "Epoch 640/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4764 - accuracy: 0.7658 - val_loss: 0.5601 - val_accuracy: 0.7113\n",
      "Epoch 641/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4800 - accuracy: 0.7608 - val_loss: 1.0356 - val_accuracy: 0.5026\n",
      "Epoch 642/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4807 - accuracy: 0.7640 - val_loss: 0.4594 - val_accuracy: 0.7708\n",
      "Epoch 643/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4784 - accuracy: 0.7645 - val_loss: 0.4590 - val_accuracy: 0.7805\n",
      "Epoch 644/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4763 - accuracy: 0.7655 - val_loss: 0.4581 - val_accuracy: 0.7716\n",
      "Epoch 645/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4772 - accuracy: 0.7680 - val_loss: 0.4885 - val_accuracy: 0.7561\n",
      "Epoch 646/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4789 - accuracy: 0.7655 - val_loss: 0.5712 - val_accuracy: 0.7071\n",
      "Epoch 647/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4779 - accuracy: 0.7668 - val_loss: 0.4537 - val_accuracy: 0.7794\n",
      "Epoch 648/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4794 - accuracy: 0.7645 - val_loss: 0.4549 - val_accuracy: 0.7775\n",
      "Epoch 649/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4773 - accuracy: 0.7632 - val_loss: 0.5335 - val_accuracy: 0.7288\n",
      "Epoch 650/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4787 - accuracy: 0.7637 - val_loss: 0.4720 - val_accuracy: 0.7667\n",
      "Epoch 651/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4791 - accuracy: 0.7648 - val_loss: 0.4648 - val_accuracy: 0.7673\n",
      "Epoch 652/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4797 - accuracy: 0.7635 - val_loss: 0.5012 - val_accuracy: 0.7405\n",
      "Epoch 653/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4801 - accuracy: 0.7627 - val_loss: 0.4690 - val_accuracy: 0.7623\n",
      "Epoch 654/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4761 - accuracy: 0.7677 - val_loss: 0.4576 - val_accuracy: 0.7807\n",
      "Epoch 655/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4769 - accuracy: 0.7649 - val_loss: 0.4833 - val_accuracy: 0.7535\n",
      "Epoch 656/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4769 - accuracy: 0.7643 - val_loss: 0.4685 - val_accuracy: 0.7643\n",
      "Epoch 657/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4793 - accuracy: 0.7627 - val_loss: 0.4572 - val_accuracy: 0.7781\n",
      "Epoch 658/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4790 - accuracy: 0.7651 - val_loss: 0.4572 - val_accuracy: 0.7788\n",
      "Epoch 659/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4773 - accuracy: 0.7660 - val_loss: 0.4884 - val_accuracy: 0.7463\n",
      "Epoch 660/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4774 - accuracy: 0.7623 - val_loss: 0.4526 - val_accuracy: 0.7792\n",
      "Epoch 661/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4760 - accuracy: 0.7677 - val_loss: 0.4648 - val_accuracy: 0.7708\n",
      "Epoch 662/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4815 - accuracy: 0.7602 - val_loss: 0.4649 - val_accuracy: 0.7630\n",
      "Epoch 663/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4750 - accuracy: 0.7671 - val_loss: 0.4934 - val_accuracy: 0.7474\n",
      "Epoch 664/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4768 - accuracy: 0.7670 - val_loss: 0.4534 - val_accuracy: 0.7777\n",
      "Epoch 665/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4784 - accuracy: 0.7633 - val_loss: 0.4732 - val_accuracy: 0.7665\n",
      "Epoch 666/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4756 - accuracy: 0.7634 - val_loss: 0.5131 - val_accuracy: 0.7418\n",
      "Epoch 667/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4795 - accuracy: 0.7612 - val_loss: 0.4764 - val_accuracy: 0.7649\n",
      "Epoch 668/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.7633 - val_loss: 0.6397 - val_accuracy: 0.6567\n",
      "Epoch 669/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7652 - val_loss: 0.4548 - val_accuracy: 0.7807\n",
      "Epoch 670/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4807 - accuracy: 0.7638 - val_loss: 0.5619 - val_accuracy: 0.7093\n",
      "Epoch 671/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7646 - val_loss: 0.4553 - val_accuracy: 0.7740\n",
      "Epoch 672/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4762 - accuracy: 0.7678 - val_loss: 0.4550 - val_accuracy: 0.7725\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7650 - val_loss: 0.4907 - val_accuracy: 0.7558\n",
      "Epoch 674/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.7636 - val_loss: 0.4574 - val_accuracy: 0.7794\n",
      "Epoch 675/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7688 - val_loss: 0.4886 - val_accuracy: 0.7541\n",
      "Epoch 676/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7665 - val_loss: 0.7149 - val_accuracy: 0.6732\n",
      "Epoch 677/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7689 - val_loss: 0.4708 - val_accuracy: 0.7686\n",
      "Epoch 678/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7676 - val_loss: 0.5664 - val_accuracy: 0.7091\n",
      "Epoch 679/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7626 - val_loss: 0.5321 - val_accuracy: 0.7264\n",
      "Epoch 680/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4792 - accuracy: 0.7633 - val_loss: 0.5331 - val_accuracy: 0.7292\n",
      "Epoch 681/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7639 - val_loss: 0.5477 - val_accuracy: 0.7212\n",
      "Epoch 682/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.7659 - val_loss: 0.4826 - val_accuracy: 0.7524\n",
      "Epoch 683/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7670 - val_loss: 0.4911 - val_accuracy: 0.7548\n",
      "Epoch 684/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7664 - val_loss: 0.4833 - val_accuracy: 0.7582\n",
      "Epoch 685/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7656 - val_loss: 0.5030 - val_accuracy: 0.7485\n",
      "Epoch 686/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.7640 - val_loss: 0.4542 - val_accuracy: 0.7781\n",
      "Epoch 687/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4747 - accuracy: 0.7677 - val_loss: 0.4671 - val_accuracy: 0.7699\n",
      "Epoch 688/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4736 - accuracy: 0.7669 - val_loss: 0.7241 - val_accuracy: 0.6177\n",
      "Epoch 689/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.7620 - val_loss: 0.5646 - val_accuracy: 0.7065\n",
      "Epoch 690/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7639 - val_loss: 0.4537 - val_accuracy: 0.7816\n",
      "Epoch 691/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4741 - accuracy: 0.7657 - val_loss: 0.4536 - val_accuracy: 0.7812\n",
      "Epoch 692/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.7648 - val_loss: 0.5407 - val_accuracy: 0.7180\n",
      "Epoch 693/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4770 - accuracy: 0.7616 - val_loss: 0.4897 - val_accuracy: 0.7535\n",
      "Epoch 694/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4743 - accuracy: 0.7676 - val_loss: 0.4779 - val_accuracy: 0.7623\n",
      "Epoch 695/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.7673 - val_loss: 0.4511 - val_accuracy: 0.7840\n",
      "Epoch 696/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7667 - val_loss: 0.4531 - val_accuracy: 0.7818\n",
      "Epoch 697/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7675 - val_loss: 0.4643 - val_accuracy: 0.7725\n",
      "Epoch 698/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7649 - val_loss: 0.4571 - val_accuracy: 0.7708\n",
      "Epoch 699/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7663 - val_loss: 0.4836 - val_accuracy: 0.7561\n",
      "Epoch 700/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7657 - val_loss: 0.7622 - val_accuracy: 0.6597\n",
      "Epoch 701/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4749 - accuracy: 0.7659 - val_loss: 0.4987 - val_accuracy: 0.7455\n",
      "Epoch 702/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4739 - accuracy: 0.7648 - val_loss: 0.4501 - val_accuracy: 0.7816\n",
      "Epoch 703/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.7639 - val_loss: 0.4921 - val_accuracy: 0.7470\n",
      "Epoch 704/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4774 - accuracy: 0.7633 - val_loss: 0.4545 - val_accuracy: 0.7801\n",
      "Epoch 705/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.7668 - val_loss: 0.6039 - val_accuracy: 0.6855\n",
      "Epoch 706/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7676 - val_loss: 0.4502 - val_accuracy: 0.7794\n",
      "Epoch 707/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7658 - val_loss: 0.4540 - val_accuracy: 0.7792\n",
      "Epoch 708/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.7645 - val_loss: 0.4643 - val_accuracy: 0.7723\n",
      "Epoch 709/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4752 - accuracy: 0.7670 - val_loss: 0.6295 - val_accuracy: 0.6885\n",
      "Epoch 710/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7687 - val_loss: 0.4740 - val_accuracy: 0.7584\n",
      "Epoch 711/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7659 - val_loss: 0.4602 - val_accuracy: 0.7684\n",
      "Epoch 712/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4749 - accuracy: 0.7661 - val_loss: 0.4571 - val_accuracy: 0.7799\n",
      "Epoch 713/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7643 - val_loss: 0.4700 - val_accuracy: 0.7634\n",
      "Epoch 714/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.7687 - val_loss: 0.4506 - val_accuracy: 0.7823\n",
      "Epoch 715/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4716 - accuracy: 0.7709 - val_loss: 0.5317 - val_accuracy: 0.7294\n",
      "Epoch 716/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7647 - val_loss: 0.4501 - val_accuracy: 0.7801\n",
      "Epoch 717/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4739 - accuracy: 0.7670 - val_loss: 0.4816 - val_accuracy: 0.7548\n",
      "Epoch 718/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7662 - val_loss: 0.4489 - val_accuracy: 0.7803\n",
      "Epoch 719/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4752 - accuracy: 0.7652 - val_loss: 0.4651 - val_accuracy: 0.7712\n",
      "Epoch 720/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4752 - accuracy: 0.7679 - val_loss: 0.4507 - val_accuracy: 0.7835\n",
      "Epoch 721/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4752 - accuracy: 0.7665 - val_loss: 0.4602 - val_accuracy: 0.7695\n",
      "Epoch 722/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7658 - val_loss: 0.4514 - val_accuracy: 0.7773\n",
      "Epoch 723/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4722 - accuracy: 0.7684 - val_loss: 0.5279 - val_accuracy: 0.7249\n",
      "Epoch 724/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7661 - val_loss: 0.4708 - val_accuracy: 0.7686\n",
      "Epoch 725/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.4502 - val_accuracy: 0.7840\n",
      "Epoch 726/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4726 - accuracy: 0.7684 - val_loss: 0.6110 - val_accuracy: 0.6827\n",
      "Epoch 727/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.7683 - val_loss: 0.4485 - val_accuracy: 0.7814\n",
      "Epoch 728/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7669 - val_loss: 0.6935 - val_accuracy: 0.6405\n",
      "Epoch 729/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7671 - val_loss: 0.4912 - val_accuracy: 0.7537\n",
      "Epoch 730/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7678 - val_loss: 0.4566 - val_accuracy: 0.7790\n",
      "Epoch 731/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7643 - val_loss: 0.6131 - val_accuracy: 0.6974\n",
      "Epoch 732/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7650 - val_loss: 0.7054 - val_accuracy: 0.6262\n",
      "Epoch 733/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4757 - accuracy: 0.7701 - val_loss: 0.4893 - val_accuracy: 0.7463\n",
      "Epoch 734/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4756 - accuracy: 0.7669 - val_loss: 0.5357 - val_accuracy: 0.7281\n",
      "Epoch 735/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4745 - accuracy: 0.7650 - val_loss: 0.4555 - val_accuracy: 0.7727\n",
      "Epoch 736/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4714 - accuracy: 0.7706 - val_loss: 0.4738 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4713 - accuracy: 0.7673 - val_loss: 0.4513 - val_accuracy: 0.7775\n",
      "Epoch 738/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4725 - accuracy: 0.7683 - val_loss: 0.4479 - val_accuracy: 0.7816\n",
      "Epoch 739/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4730 - accuracy: 0.7653 - val_loss: 0.5039 - val_accuracy: 0.7429\n",
      "Epoch 740/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4744 - accuracy: 0.7674 - val_loss: 0.5622 - val_accuracy: 0.7030\n",
      "Epoch 741/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4728 - accuracy: 0.7680 - val_loss: 0.4532 - val_accuracy: 0.7805\n",
      "Epoch 742/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4741 - accuracy: 0.7678 - val_loss: 0.5274 - val_accuracy: 0.7247\n",
      "Epoch 743/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7658 - val_loss: 0.4575 - val_accuracy: 0.7788\n",
      "Epoch 744/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4722 - accuracy: 0.7691 - val_loss: 0.6232 - val_accuracy: 0.6937\n",
      "Epoch 745/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4743 - accuracy: 0.7659 - val_loss: 0.4502 - val_accuracy: 0.7753\n",
      "Epoch 746/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4743 - accuracy: 0.7641 - val_loss: 0.4677 - val_accuracy: 0.7708\n",
      "Epoch 747/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4724 - accuracy: 0.7659 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 748/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.7656 - val_loss: 0.5363 - val_accuracy: 0.7258\n",
      "Epoch 749/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4771 - accuracy: 0.7673 - val_loss: 0.4499 - val_accuracy: 0.7792\n",
      "Epoch 750/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4771 - accuracy: 0.7645 - val_loss: 0.4493 - val_accuracy: 0.7848\n",
      "Epoch 751/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7671 - val_loss: 0.4784 - val_accuracy: 0.7626\n",
      "Epoch 752/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4707 - accuracy: 0.7706 - val_loss: 0.4635 - val_accuracy: 0.7751\n",
      "Epoch 753/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4756 - accuracy: 0.7671 - val_loss: 0.4660 - val_accuracy: 0.7658\n",
      "Epoch 754/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4738 - accuracy: 0.7666 - val_loss: 0.4472 - val_accuracy: 0.7825\n",
      "Epoch 755/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.7690 - val_loss: 0.4548 - val_accuracy: 0.7792\n",
      "Epoch 756/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.7671 - val_loss: 0.4584 - val_accuracy: 0.7703\n",
      "Epoch 757/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.7655 - val_loss: 0.4484 - val_accuracy: 0.7829\n",
      "Epoch 758/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4747 - accuracy: 0.7670 - val_loss: 0.4703 - val_accuracy: 0.7597\n",
      "Epoch 759/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7662 - val_loss: 0.4488 - val_accuracy: 0.7803\n",
      "Epoch 760/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7664 - val_loss: 0.4855 - val_accuracy: 0.7591\n",
      "Epoch 761/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7720 - val_loss: 0.4567 - val_accuracy: 0.7697\n",
      "Epoch 762/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4735 - accuracy: 0.7668 - val_loss: 0.5224 - val_accuracy: 0.7346\n",
      "Epoch 763/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4704 - accuracy: 0.7705 - val_loss: 0.4478 - val_accuracy: 0.7810\n",
      "Epoch 764/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4728 - accuracy: 0.7709 - val_loss: 0.5539 - val_accuracy: 0.7134\n",
      "Epoch 765/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4744 - accuracy: 0.7669 - val_loss: 0.4563 - val_accuracy: 0.7792\n",
      "Epoch 766/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.7709 - val_loss: 0.4481 - val_accuracy: 0.7823\n",
      "Epoch 767/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4741 - accuracy: 0.7678 - val_loss: 0.6262 - val_accuracy: 0.6667\n",
      "Epoch 768/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4723 - accuracy: 0.7656 - val_loss: 0.4726 - val_accuracy: 0.7621\n",
      "Epoch 769/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4729 - accuracy: 0.7673 - val_loss: 0.4471 - val_accuracy: 0.7877\n",
      "Epoch 770/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7682 - val_loss: 0.4517 - val_accuracy: 0.7820\n",
      "Epoch 771/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4743 - accuracy: 0.7682 - val_loss: 0.5801 - val_accuracy: 0.7024\n",
      "Epoch 772/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7643 - val_loss: 0.4768 - val_accuracy: 0.7584\n",
      "Epoch 773/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.7705 - val_loss: 0.4453 - val_accuracy: 0.7861\n",
      "Epoch 774/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4751 - accuracy: 0.7672 - val_loss: 0.4864 - val_accuracy: 0.7563\n",
      "Epoch 775/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4735 - accuracy: 0.7699 - val_loss: 0.4746 - val_accuracy: 0.7652\n",
      "Epoch 776/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7688 - val_loss: 0.4908 - val_accuracy: 0.7502\n",
      "Epoch 777/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4740 - accuracy: 0.7645 - val_loss: 0.5065 - val_accuracy: 0.7353\n",
      "Epoch 778/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4710 - accuracy: 0.7687 - val_loss: 0.4698 - val_accuracy: 0.7690\n",
      "Epoch 779/1000\n",
      "578/578 [==============================] - 1s 1ms/step - loss: 0.4718 - accuracy: 0.7690 - val_loss: 0.5020 - val_accuracy: 0.7472\n",
      "Epoch 780/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4721 - accuracy: 0.7718 - val_loss: 0.5972 - val_accuracy: 0.6989\n",
      "Epoch 781/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4716 - accuracy: 0.7688 - val_loss: 0.6021 - val_accuracy: 0.6944\n",
      "Epoch 782/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4762 - accuracy: 0.7657 - val_loss: 0.4564 - val_accuracy: 0.7706\n",
      "Epoch 783/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4734 - accuracy: 0.7688 - val_loss: 0.4492 - val_accuracy: 0.7803\n",
      "Epoch 784/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4710 - accuracy: 0.7685 - val_loss: 0.4951 - val_accuracy: 0.7498\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4736 - accuracy: 0.7656 - val_loss: 0.4643 - val_accuracy: 0.7742\n",
      "Epoch 786/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4763 - accuracy: 0.7642 - val_loss: 0.4753 - val_accuracy: 0.7658\n",
      "Epoch 787/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4722 - accuracy: 0.7704 - val_loss: 0.4849 - val_accuracy: 0.7481\n",
      "Epoch 788/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4721 - accuracy: 0.7692 - val_loss: 0.4713 - val_accuracy: 0.7617\n",
      "Epoch 789/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4707 - accuracy: 0.7693 - val_loss: 0.6008 - val_accuracy: 0.6881\n",
      "Epoch 790/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.7693 - val_loss: 0.4447 - val_accuracy: 0.7833\n",
      "Epoch 791/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4730 - accuracy: 0.7663 - val_loss: 0.4927 - val_accuracy: 0.7483\n",
      "Epoch 792/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4732 - accuracy: 0.7684 - val_loss: 0.5419 - val_accuracy: 0.7249\n",
      "Epoch 793/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4727 - accuracy: 0.7672 - val_loss: 0.4472 - val_accuracy: 0.7833\n",
      "Epoch 794/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.7697 - val_loss: 0.4516 - val_accuracy: 0.7764\n",
      "Epoch 795/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.7665 - val_loss: 0.4641 - val_accuracy: 0.7671\n",
      "Epoch 796/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4725 - accuracy: 0.7692 - val_loss: 0.5694 - val_accuracy: 0.7113\n",
      "Epoch 797/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4734 - accuracy: 0.7680 - val_loss: 0.5439 - val_accuracy: 0.7160\n",
      "Epoch 798/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.9314 - val_accuracy: 0.5277\n",
      "Epoch 799/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4731 - accuracy: 0.7676 - val_loss: 0.4657 - val_accuracy: 0.7747\n",
      "Epoch 800/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.4979 - val_accuracy: 0.7494\n",
      "Epoch 801/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.7665 - val_loss: 0.4634 - val_accuracy: 0.7665\n",
      "Epoch 802/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7693 - val_loss: 0.4448 - val_accuracy: 0.7820\n",
      "Epoch 803/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4707 - accuracy: 0.7681 - val_loss: 0.4797 - val_accuracy: 0.7628\n",
      "Epoch 804/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.7707 - val_loss: 0.4525 - val_accuracy: 0.7807\n",
      "Epoch 805/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4721 - accuracy: 0.7692 - val_loss: 0.4431 - val_accuracy: 0.7894\n",
      "Epoch 806/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4729 - accuracy: 0.7663 - val_loss: 0.4458 - val_accuracy: 0.7872\n",
      "Epoch 807/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4726 - accuracy: 0.7724 - val_loss: 0.4723 - val_accuracy: 0.7693\n",
      "Epoch 808/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4727 - accuracy: 0.7654 - val_loss: 0.5323 - val_accuracy: 0.7260\n",
      "Epoch 809/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4723 - accuracy: 0.7656 - val_loss: 0.6061 - val_accuracy: 0.6955\n",
      "Epoch 810/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4690 - accuracy: 0.7694 - val_loss: 0.6095 - val_accuracy: 0.6777\n",
      "Epoch 811/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4708 - accuracy: 0.7718 - val_loss: 0.4599 - val_accuracy: 0.7703\n",
      "Epoch 812/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4700 - accuracy: 0.7673 - val_loss: 0.9102 - val_accuracy: 0.5444\n",
      "Epoch 813/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4707 - accuracy: 0.7712 - val_loss: 0.4740 - val_accuracy: 0.7677\n",
      "Epoch 814/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4729 - accuracy: 0.7675 - val_loss: 0.4430 - val_accuracy: 0.7896\n",
      "Epoch 815/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4748 - accuracy: 0.7658 - val_loss: 0.5309 - val_accuracy: 0.7325\n",
      "Epoch 816/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4680 - accuracy: 0.7711 - val_loss: 0.4473 - val_accuracy: 0.7805\n",
      "Epoch 817/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4723 - accuracy: 0.7675 - val_loss: 0.4692 - val_accuracy: 0.7606\n",
      "Epoch 818/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.7700 - val_loss: 0.4499 - val_accuracy: 0.7751\n",
      "Epoch 819/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4725 - accuracy: 0.7697 - val_loss: 0.4422 - val_accuracy: 0.7848\n",
      "Epoch 820/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4724 - accuracy: 0.7689 - val_loss: 0.4651 - val_accuracy: 0.7660\n",
      "Epoch 821/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.7002 - val_accuracy: 0.6314\n",
      "Epoch 822/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4727 - accuracy: 0.7658 - val_loss: 0.6655 - val_accuracy: 0.6509\n",
      "Epoch 823/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4727 - accuracy: 0.7702 - val_loss: 0.4742 - val_accuracy: 0.7580\n",
      "Epoch 824/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4704 - accuracy: 0.7696 - val_loss: 0.5325 - val_accuracy: 0.7301\n",
      "Epoch 825/1000\n",
      "578/578 [==============================] - 2s 4ms/step - loss: 0.4687 - accuracy: 0.7697 - val_loss: 0.6291 - val_accuracy: 0.6693\n",
      "Epoch 826/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4692 - accuracy: 0.7699 - val_loss: 0.4474 - val_accuracy: 0.7859\n",
      "Epoch 827/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4745 - accuracy: 0.7644 - val_loss: 0.6737 - val_accuracy: 0.6416\n",
      "Epoch 828/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4702 - accuracy: 0.7682 - val_loss: 0.5519 - val_accuracy: 0.7132\n",
      "Epoch 829/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4707 - accuracy: 0.7688 - val_loss: 0.4540 - val_accuracy: 0.7729\n",
      "Epoch 830/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4700 - accuracy: 0.7702 - val_loss: 0.5126 - val_accuracy: 0.7327\n",
      "Epoch 831/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7689 - val_loss: 0.5162 - val_accuracy: 0.7374\n",
      "Epoch 832/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4730 - accuracy: 0.7690 - val_loss: 0.4463 - val_accuracy: 0.7842\n",
      "Epoch 833/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4702 - accuracy: 0.7705 - val_loss: 0.5857 - val_accuracy: 0.6985\n",
      "Epoch 834/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4692 - accuracy: 0.7684 - val_loss: 0.4548 - val_accuracy: 0.7823\n",
      "Epoch 835/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4452 - val_accuracy: 0.7805\n",
      "Epoch 836/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4690 - accuracy: 0.7692 - val_loss: 0.5572 - val_accuracy: 0.7119\n",
      "Epoch 837/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.7668 - val_loss: 0.5264 - val_accuracy: 0.7299\n",
      "Epoch 838/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4688 - accuracy: 0.7712 - val_loss: 0.4417 - val_accuracy: 0.7866\n",
      "Epoch 839/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4668 - accuracy: 0.7674 - val_loss: 0.4490 - val_accuracy: 0.7768\n",
      "Epoch 840/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4727 - accuracy: 0.7682 - val_loss: 0.5003 - val_accuracy: 0.7474\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4703 - accuracy: 0.7680 - val_loss: 0.4460 - val_accuracy: 0.7784\n",
      "Epoch 842/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4708 - accuracy: 0.7683 - val_loss: 0.4688 - val_accuracy: 0.7716\n",
      "Epoch 843/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4696 - accuracy: 0.7688 - val_loss: 0.4964 - val_accuracy: 0.7435\n",
      "Epoch 844/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.7680 - val_loss: 0.4437 - val_accuracy: 0.7827\n",
      "Epoch 845/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4710 - accuracy: 0.7695 - val_loss: 0.4895 - val_accuracy: 0.7539\n",
      "Epoch 846/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4699 - accuracy: 0.7683 - val_loss: 0.4504 - val_accuracy: 0.7742\n",
      "Epoch 847/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4721 - accuracy: 0.7682 - val_loss: 0.5504 - val_accuracy: 0.7154\n",
      "Epoch 848/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4707 - accuracy: 0.7687 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 849/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4683 - accuracy: 0.7705 - val_loss: 0.4810 - val_accuracy: 0.7595\n",
      "Epoch 850/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4729 - accuracy: 0.7687 - val_loss: 0.4758 - val_accuracy: 0.7584\n",
      "Epoch 851/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.7685 - val_loss: 0.5801 - val_accuracy: 0.6955\n",
      "Epoch 852/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4702 - accuracy: 0.7673 - val_loss: 0.4416 - val_accuracy: 0.7857\n",
      "Epoch 853/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.7706 - val_loss: 0.5612 - val_accuracy: 0.7154\n",
      "Epoch 854/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7416\n",
      "Epoch 855/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7716 - val_loss: 0.5930 - val_accuracy: 0.6840\n",
      "Epoch 856/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.7686 - val_loss: 0.4954 - val_accuracy: 0.7506\n",
      "Epoch 857/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.7700 - val_loss: 0.6420 - val_accuracy: 0.6578\n",
      "Epoch 858/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.7688 - val_loss: 0.4424 - val_accuracy: 0.7877\n",
      "Epoch 859/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4697 - accuracy: 0.7688 - val_loss: 0.4410 - val_accuracy: 0.7883\n",
      "Epoch 860/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.7688 - val_loss: 0.4400 - val_accuracy: 0.7898\n",
      "Epoch 861/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4605 - val_accuracy: 0.7784\n",
      "Epoch 862/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4724 - accuracy: 0.7707 - val_loss: 0.5528 - val_accuracy: 0.7186\n",
      "Epoch 863/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7720 - val_loss: 0.4543 - val_accuracy: 0.7827\n",
      "Epoch 864/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.7704 - val_loss: 0.4405 - val_accuracy: 0.7879\n",
      "Epoch 865/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4740 - accuracy: 0.7677 - val_loss: 0.5218 - val_accuracy: 0.7292\n",
      "Epoch 866/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4680 - accuracy: 0.7719 - val_loss: 0.5000 - val_accuracy: 0.7411\n",
      "Epoch 867/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7686 - val_loss: 0.4428 - val_accuracy: 0.7905\n",
      "Epoch 868/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7714 - val_loss: 0.4438 - val_accuracy: 0.7825\n",
      "Epoch 869/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.7696 - val_loss: 0.4480 - val_accuracy: 0.7833\n",
      "Epoch 870/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4710 - accuracy: 0.7680 - val_loss: 0.5192 - val_accuracy: 0.7372\n",
      "Epoch 871/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7682 - val_loss: 0.4474 - val_accuracy: 0.7838\n",
      "Epoch 872/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7762 - val_loss: 0.4687 - val_accuracy: 0.7643\n",
      "Epoch 873/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4699 - accuracy: 0.7706 - val_loss: 0.4638 - val_accuracy: 0.7667\n",
      "Epoch 874/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4680 - accuracy: 0.7704 - val_loss: 0.6076 - val_accuracy: 0.6825\n",
      "Epoch 875/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4683 - accuracy: 0.7706 - val_loss: 0.4614 - val_accuracy: 0.7753\n",
      "Epoch 876/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4685 - accuracy: 0.7701 - val_loss: 0.4926 - val_accuracy: 0.7446\n",
      "Epoch 877/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7737 - val_loss: 0.4426 - val_accuracy: 0.7918\n",
      "Epoch 878/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4715 - accuracy: 0.7675 - val_loss: 0.5417 - val_accuracy: 0.7219\n",
      "Epoch 879/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4685 - accuracy: 0.7716 - val_loss: 0.4671 - val_accuracy: 0.7712\n",
      "Epoch 880/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4677 - accuracy: 0.7718 - val_loss: 0.5751 - val_accuracy: 0.7097\n",
      "Epoch 881/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7697 - val_loss: 0.4602 - val_accuracy: 0.7801\n",
      "Epoch 882/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.7695 - val_loss: 0.5499 - val_accuracy: 0.7160\n",
      "Epoch 883/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4694 - accuracy: 0.7713 - val_loss: 0.5509 - val_accuracy: 0.7143\n",
      "Epoch 884/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7718 - val_loss: 0.5273 - val_accuracy: 0.7279\n",
      "Epoch 885/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7709 - val_loss: 0.4484 - val_accuracy: 0.7838\n",
      "Epoch 886/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4711 - accuracy: 0.7696 - val_loss: 0.4776 - val_accuracy: 0.7537\n",
      "Epoch 887/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7720 - val_loss: 0.4366 - val_accuracy: 0.7918\n",
      "Epoch 888/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.7664 - val_loss: 0.5190 - val_accuracy: 0.7359\n",
      "Epoch 889/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7738 - val_loss: 0.4377 - val_accuracy: 0.7896\n",
      "Epoch 890/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4677 - accuracy: 0.7725 - val_loss: 0.4399 - val_accuracy: 0.7844\n",
      "Epoch 891/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4707 - accuracy: 0.7694 - val_loss: 0.4942 - val_accuracy: 0.7498\n",
      "Epoch 892/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4666 - accuracy: 0.7717 - val_loss: 0.4500 - val_accuracy: 0.7784\n",
      "Epoch 893/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4722 - accuracy: 0.7654 - val_loss: 0.6664 - val_accuracy: 0.6470\n",
      "Epoch 894/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4692 - accuracy: 0.7722 - val_loss: 0.5194 - val_accuracy: 0.7353\n",
      "Epoch 895/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4640 - accuracy: 0.7764 - val_loss: 0.4984 - val_accuracy: 0.7465\n",
      "Epoch 896/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4683 - accuracy: 0.7714 - val_loss: 0.4644 - val_accuracy: 0.7732\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.7686 - val_loss: 0.4499 - val_accuracy: 0.7751\n",
      "Epoch 898/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4712 - accuracy: 0.7709 - val_loss: 0.4438 - val_accuracy: 0.7881\n",
      "Epoch 899/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4679 - accuracy: 0.7704 - val_loss: 0.4895 - val_accuracy: 0.7457\n",
      "Epoch 900/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4698 - accuracy: 0.7709 - val_loss: 0.6197 - val_accuracy: 0.6762\n",
      "Epoch 901/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7746 - val_loss: 0.4768 - val_accuracy: 0.7545\n",
      "Epoch 902/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4648 - accuracy: 0.7727 - val_loss: 0.4847 - val_accuracy: 0.7494\n",
      "Epoch 903/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4690 - accuracy: 0.7705 - val_loss: 0.4469 - val_accuracy: 0.7803\n",
      "Epoch 904/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.7720 - val_loss: 0.5359 - val_accuracy: 0.7253\n",
      "Epoch 905/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7751 - val_loss: 0.4406 - val_accuracy: 0.7900\n",
      "Epoch 906/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7728 - val_loss: 0.4421 - val_accuracy: 0.7825\n",
      "Epoch 907/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4701 - accuracy: 0.7679 - val_loss: 0.8254 - val_accuracy: 0.5749\n",
      "Epoch 908/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4701 - accuracy: 0.7692 - val_loss: 0.4913 - val_accuracy: 0.7526\n",
      "Epoch 909/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7710 - val_loss: 0.4444 - val_accuracy: 0.7851\n",
      "Epoch 910/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4722 - accuracy: 0.7679 - val_loss: 0.6165 - val_accuracy: 0.6883\n",
      "Epoch 911/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4666 - accuracy: 0.7741 - val_loss: 0.4422 - val_accuracy: 0.7896\n",
      "Epoch 912/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7709 - val_loss: 0.4815 - val_accuracy: 0.7591\n",
      "Epoch 913/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7707 - val_loss: 0.5117 - val_accuracy: 0.7392\n",
      "Epoch 914/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7701 - val_loss: 0.4602 - val_accuracy: 0.7675\n",
      "Epoch 915/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4642 - accuracy: 0.7750 - val_loss: 0.4410 - val_accuracy: 0.7885\n",
      "Epoch 916/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4852 - val_accuracy: 0.7470\n",
      "Epoch 917/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4645 - accuracy: 0.7712 - val_loss: 0.4482 - val_accuracy: 0.7764\n",
      "Epoch 918/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4714 - accuracy: 0.7712 - val_loss: 0.5114 - val_accuracy: 0.7338\n",
      "Epoch 919/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4671 - accuracy: 0.7719 - val_loss: 0.5144 - val_accuracy: 0.7329\n",
      "Epoch 920/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4711 - accuracy: 0.7696 - val_loss: 0.4811 - val_accuracy: 0.7643\n",
      "Epoch 921/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4666 - accuracy: 0.7733 - val_loss: 0.4403 - val_accuracy: 0.7864\n",
      "Epoch 922/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.7716 - val_loss: 0.4558 - val_accuracy: 0.7695\n",
      "Epoch 923/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.7728 - val_loss: 0.5287 - val_accuracy: 0.7223\n",
      "Epoch 924/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4656 - accuracy: 0.7749 - val_loss: 0.4510 - val_accuracy: 0.7738\n",
      "Epoch 925/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4683 - accuracy: 0.7708 - val_loss: 0.4523 - val_accuracy: 0.7835\n",
      "Epoch 926/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4611 - accuracy: 0.7765 - val_loss: 0.4537 - val_accuracy: 0.7840\n",
      "Epoch 927/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4705 - accuracy: 0.7721 - val_loss: 0.4474 - val_accuracy: 0.7749\n",
      "Epoch 928/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4661 - accuracy: 0.7719 - val_loss: 0.4535 - val_accuracy: 0.7716\n",
      "Epoch 929/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4650 - accuracy: 0.7684 - val_loss: 0.5642 - val_accuracy: 0.7104\n",
      "Epoch 930/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4676 - accuracy: 0.7709 - val_loss: 0.6453 - val_accuracy: 0.6846\n",
      "Epoch 931/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4685 - accuracy: 0.7696 - val_loss: 0.4373 - val_accuracy: 0.7933\n",
      "Epoch 932/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4671 - accuracy: 0.7706 - val_loss: 0.6286 - val_accuracy: 0.6931\n",
      "Epoch 933/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4681 - accuracy: 0.7708 - val_loss: 0.7813 - val_accuracy: 0.6515\n",
      "Epoch 934/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4664 - accuracy: 0.7733 - val_loss: 0.4483 - val_accuracy: 0.7755\n",
      "Epoch 935/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4676 - accuracy: 0.7694 - val_loss: 0.5153 - val_accuracy: 0.7262\n",
      "Epoch 936/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4642 - accuracy: 0.7713 - val_loss: 0.4428 - val_accuracy: 0.7883\n",
      "Epoch 937/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4677 - accuracy: 0.7724 - val_loss: 0.5003 - val_accuracy: 0.7478\n",
      "Epoch 938/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4655 - accuracy: 0.7699 - val_loss: 0.4381 - val_accuracy: 0.7877\n",
      "Epoch 939/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4627 - accuracy: 0.7731 - val_loss: 0.5361 - val_accuracy: 0.7210\n",
      "Epoch 940/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4687 - accuracy: 0.7697 - val_loss: 0.5090 - val_accuracy: 0.7392\n",
      "Epoch 941/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4667 - accuracy: 0.7731 - val_loss: 0.4390 - val_accuracy: 0.7848\n",
      "Epoch 942/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4668 - accuracy: 0.7683 - val_loss: 0.4427 - val_accuracy: 0.7816\n",
      "Epoch 943/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4639 - accuracy: 0.7745 - val_loss: 0.4479 - val_accuracy: 0.7758\n",
      "Epoch 944/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4672 - accuracy: 0.7712 - val_loss: 0.4421 - val_accuracy: 0.7829\n",
      "Epoch 945/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4656 - accuracy: 0.7709 - val_loss: 0.4353 - val_accuracy: 0.7911\n",
      "Epoch 946/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7735 - val_loss: 0.4472 - val_accuracy: 0.7868\n",
      "Epoch 947/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4661 - accuracy: 0.7722 - val_loss: 0.5001 - val_accuracy: 0.7413\n",
      "Epoch 948/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4649 - accuracy: 0.7728 - val_loss: 0.5409 - val_accuracy: 0.7152\n",
      "Epoch 949/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4651 - accuracy: 0.7715 - val_loss: 0.4362 - val_accuracy: 0.7946\n",
      "Epoch 950/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7717 - val_loss: 0.5128 - val_accuracy: 0.7338\n",
      "Epoch 951/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4688 - accuracy: 0.7699 - val_loss: 0.4376 - val_accuracy: 0.7870\n",
      "Epoch 952/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7753 - val_loss: 0.7222 - val_accuracy: 0.6708\n",
      "Epoch 953/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4672 - accuracy: 0.7689 - val_loss: 0.5335 - val_accuracy: 0.7253\n",
      "Epoch 954/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4659 - accuracy: 0.7734 - val_loss: 0.5581 - val_accuracy: 0.7093\n",
      "Epoch 955/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4636 - accuracy: 0.7740 - val_loss: 0.4630 - val_accuracy: 0.7773\n",
      "Epoch 956/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4689 - accuracy: 0.7712 - val_loss: 0.4615 - val_accuracy: 0.7766\n",
      "Epoch 957/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4658 - accuracy: 0.7748 - val_loss: 0.5814 - val_accuracy: 0.6924\n",
      "Epoch 958/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4651 - accuracy: 0.7724 - val_loss: 0.6550 - val_accuracy: 0.6504\n",
      "Epoch 959/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4659 - accuracy: 0.7715 - val_loss: 0.5526 - val_accuracy: 0.7186\n",
      "Epoch 960/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7732 - val_loss: 0.4961 - val_accuracy: 0.7509\n",
      "Epoch 961/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.7731 - val_loss: 0.4476 - val_accuracy: 0.7861\n",
      "Epoch 962/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7740 - val_loss: 0.4426 - val_accuracy: 0.7885\n",
      "Epoch 963/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4668 - accuracy: 0.7703 - val_loss: 0.4408 - val_accuracy: 0.7909\n",
      "Epoch 964/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4664 - accuracy: 0.7691 - val_loss: 0.4414 - val_accuracy: 0.7840\n",
      "Epoch 965/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4644 - accuracy: 0.7745 - val_loss: 0.4378 - val_accuracy: 0.7898\n",
      "Epoch 966/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4666 - accuracy: 0.7709 - val_loss: 0.4338 - val_accuracy: 0.7937\n",
      "Epoch 967/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4665 - accuracy: 0.7718 - val_loss: 0.4499 - val_accuracy: 0.7758\n",
      "Epoch 968/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.7714 - val_loss: 0.4899 - val_accuracy: 0.7485\n",
      "Epoch 969/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.7709 - val_loss: 0.4665 - val_accuracy: 0.7617\n",
      "Epoch 970/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4652 - accuracy: 0.7764 - val_loss: 0.4888 - val_accuracy: 0.7576\n",
      "Epoch 971/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4665 - accuracy: 0.7723 - val_loss: 0.4349 - val_accuracy: 0.7935\n",
      "Epoch 972/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4618 - accuracy: 0.7738 - val_loss: 0.4612 - val_accuracy: 0.7753\n",
      "Epoch 973/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4650 - accuracy: 0.7729 - val_loss: 0.4944 - val_accuracy: 0.7517\n",
      "Epoch 974/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.7724 - val_loss: 0.5061 - val_accuracy: 0.7435\n",
      "Epoch 975/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4645 - accuracy: 0.7743 - val_loss: 0.4679 - val_accuracy: 0.7721\n",
      "Epoch 976/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4689 - accuracy: 0.7685 - val_loss: 0.5967 - val_accuracy: 0.6864\n",
      "Epoch 977/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4654 - accuracy: 0.7737 - val_loss: 0.4896 - val_accuracy: 0.7459\n",
      "Epoch 978/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.7735 - val_loss: 0.4716 - val_accuracy: 0.7578\n",
      "Epoch 979/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4646 - accuracy: 0.7747 - val_loss: 0.4593 - val_accuracy: 0.7790\n",
      "Epoch 980/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.7723 - val_loss: 0.4361 - val_accuracy: 0.7874\n",
      "Epoch 981/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4636 - accuracy: 0.7749 - val_loss: 0.5545 - val_accuracy: 0.7141\n",
      "Epoch 982/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4664 - accuracy: 0.7714 - val_loss: 0.4416 - val_accuracy: 0.7833\n",
      "Epoch 983/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7702 - val_loss: 0.4779 - val_accuracy: 0.7634\n",
      "Epoch 984/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4680 - accuracy: 0.7695 - val_loss: 0.5122 - val_accuracy: 0.7279\n",
      "Epoch 985/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.7737 - val_loss: 0.4847 - val_accuracy: 0.7496\n",
      "Epoch 986/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7714 - val_loss: 0.4902 - val_accuracy: 0.7558\n",
      "Epoch 987/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4660 - accuracy: 0.7751 - val_loss: 0.4344 - val_accuracy: 0.7900\n",
      "Epoch 988/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7732 - val_loss: 0.4447 - val_accuracy: 0.7883\n",
      "Epoch 989/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7722 - val_loss: 0.4969 - val_accuracy: 0.7459\n",
      "Epoch 990/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7711 - val_loss: 0.5053 - val_accuracy: 0.7437\n",
      "Epoch 991/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4687 - accuracy: 0.7727 - val_loss: 0.6692 - val_accuracy: 0.6487\n",
      "Epoch 992/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.7763 - val_loss: 0.4686 - val_accuracy: 0.7712\n",
      "Epoch 993/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.7741 - val_loss: 0.4659 - val_accuracy: 0.7621\n",
      "Epoch 994/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7701 - val_loss: 0.7537 - val_accuracy: 0.6041\n",
      "Epoch 995/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7728 - val_loss: 0.4368 - val_accuracy: 0.7868\n",
      "Epoch 996/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7744 - val_loss: 0.5508 - val_accuracy: 0.7128\n",
      "Epoch 997/1000\n",
      "578/578 [==============================] - 2s 3ms/step - loss: 0.4671 - accuracy: 0.7698 - val_loss: 0.4397 - val_accuracy: 0.7903\n",
      "Epoch 998/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4607 - accuracy: 0.7750 - val_loss: 0.4417 - val_accuracy: 0.7900\n",
      "Epoch 999/1000\n",
      "578/578 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.7694 - val_loss: 0.5555 - val_accuracy: 0.7106\n",
      "Epoch 1000/1000\n",
      "578/578 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.7770 - val_loss: 0.4357 - val_accuracy: 0.7877\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.788\n",
      "roc-auc is 0.874\n"
     ]
    }
   ],
   "source": [
    "y_pred_class_nn_1 = model_1.predict_classes(X_test)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the different models and parameters\n",
    "\n",
    "RandomForest has the best score among all of the models:\n",
    "- accuracy is 0.830\n",
    "- roc-auc is 0.910\n",
    "\n",
    "Among all the Neural Network with the different parameters, the one with two hidden layers and epochs 1000 gave the best results:\n",
    "\n",
    "- accuracy is 0.788\n",
    "- roc-auc is 0.874\n",
    "\n",
    "In conclusion, depending on what we are trying to predict in this case RandomForest model is the most suitable for predicting team win or loss.\n",
    "\n",
    "Neural Network may give better results as we increase the number of epochs but the performance will be impacted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
